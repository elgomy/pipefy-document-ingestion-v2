#!/usr/bin/env python3
"""
Servicio de Ingesti√≥n de Documentos - Versi√≥n HTTP Directa
Se enfoca √∫nicamente en procesar documentos de Pipefy y almacenarlos en Supabase.
Usa comunicaci√≥n HTTP directa con el servicio CrewAI.
MANTIENE LA MODULARIDAD: Cada servicio tiene su responsabilidad espec√≠fica.
"""

import os
import asyncio
import tempfile
import httpx
import logging
import hmac
import hashlib
from contextlib import asynccontextmanager
from typing import List, Optional, Dict, Any, Union
from fastapi import FastAPI, HTTPException, Request, Header, BackgroundTasks
from pydantic import BaseModel, field_validator, model_validator
from supabase import create_client, Client
from dotenv import load_dotenv
import json
from datetime import datetime

# Cargar variables de entorno
load_dotenv()

# Importar settings de configuraci√≥n
from src.config.settings import settings

# Configuraci√≥n de logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Variables de entorno
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_SERVICE_KEY = os.getenv("SUPABASE_SERVICE_KEY")
SUPABASE_STORAGE_BUCKET_NAME = os.getenv("SUPABASE_STORAGE_BUCKET_NAME", "documents")
PIPEFY_TOKEN = os.getenv("PIPEFY_TOKEN")
PIPEFY_WEBHOOK_SECRET = os.getenv("PIPEFY_WEBHOOK_SECRET")

# üîó COMUNICACI√ìN HTTP DIRECTA - URL del servicio CrewAI
CREWAI_SERVICE_URL = os.getenv("CREWAI_SERVICE_URL", "https://pipefy-crewai-analysis-modular.onrender.com")

# üÜï NUEVAS VARIABLES PARA INTEGRACI√ìN SEG√öN PRD
TWILIO_ACCOUNT_SID = os.getenv("TWILIO_ACCOUNT_SID")
TWILIO_AUTH_TOKEN = os.getenv("TWILIO_AUTH_TOKEN")
TWILIO_WHATSAPP_NUMBER = os.getenv("TWILIO_WHATSAPP_NUMBER", "+17245586619")
CNPJA_API_KEY = os.getenv("CNPJA_API_KEY")

# üéØ IDs DE FASES DE PIPEFY SEG√öN PRD (usando settings)
PHASE_ID_TRIAGEM = "338000020"  # Triagem Documentos AI (fijo para webhook)
# Los dem√°s ahora vienen de settings para flexibilidad
PHASE_ID_PENDENCIAS = settings.PHASE_ID_PENDENCIAS
PHASE_ID_EMITIR_DOCS = settings.PHASE_ID_EMITIR_DOCS
PHASE_ID_APROVADO = settings.PHASE_ID_APROVADO

# üìã CONSTANTES DE PIPEFY API
PIPEFY_API_URL = "https://api.pipefy.com/graphql"

# Cliente Supabase global
supabase_client: Optional[Client] = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Gerencia o ciclo de vida da aplica√ß√£o FastAPI."""
    global supabase_client
    
    # Startup
    logger.info("üöÄ Iniciando Servicio de Ingesti√≥n de Documentos (HTTP Directo)...")
    
    if not SUPABASE_URL or not SUPABASE_SERVICE_KEY:
        logger.error("ERRO: Vari√°veis SUPABASE_URL e SUPABASE_SERVICE_KEY s√£o obrigat√≥rias.")
        raise RuntimeError("Configura√ß√£o Supabase incompleta.")
    
    if not PIPEFY_TOKEN:
        logger.error("ERRO: Vari√°vel PIPEFY_TOKEN √© obrigat√≥ria.")
        raise RuntimeError("Token Pipefy n√£o configurado.")
    
    try:
        supabase_client = create_client(SUPABASE_URL, SUPABASE_SERVICE_KEY)
        logger.info("‚úÖ Cliente Supabase inicializado com sucesso.")
    except Exception as e:
        logger.error(f"ERRO ao inicializar cliente Supabase: {e}")
        raise RuntimeError(f"Falha na inicializa√ß√£o do Supabase: {e}")
    
    logger.info(f"üîó Servicio CrewAI configurado en: {CREWAI_SERVICE_URL}")
    
    yield
    
    # Shutdown
    logger.info("INFO: Encerrando Servicio de Ingesti√≥n de Documentos...")

app = FastAPI(
    lifespan=lifespan, 
    title="Document Ingestion Service - HTTP Direct",
    description="Servicio modular para ingesti√≥n de documentos con comunicaci√≥n HTTP directa"
)

# Modelos Pydantic
class PipefyCard(BaseModel):
    model_config = {"extra": "allow"}
    
    id: str
    title: Optional[str] = None
    current_phase: Optional[Dict[str, Any]] = None
    pipe: Optional[Dict[str, Any]] = None
    fields: Optional[List[Dict[str, Any]]] = None
    
    @model_validator(mode='before')
    @classmethod
    def convert_id_to_string(cls, data):
        if isinstance(data, dict) and 'id' in data:
            data['id'] = str(data['id'])
        return data

class PipefyEventData(BaseModel):
    model_config = {"extra": "allow"}
    card: PipefyCard
    action: Optional[str] = None

class PipefyWebhookPayload(BaseModel):
    model_config = {"extra": "allow"}
    data: PipefyEventData

class PipefyAttachment(BaseModel):
    name: str
    path: str

# üîó Modelo para comunicaci√≥n HTTP directa con CrewAI
class CrewAIAnalysisRequest(BaseModel):
    case_id: str
    documents: List[Dict[str, Any]]
    checklist_url: str
    current_date: str
    pipe_id: Optional[str] = None

# üìã Modelos para Webhook de Supabase
class SupabaseWebhookPayload(BaseModel):
    """Modelo para el payload del webhook de Supabase"""
    type: str  # INSERT, UPDATE, DELETE
    table: str
    schema: str
    record: Optional[Dict[str, Any]] = None
    old_record: Optional[Dict[str, Any]] = None

# üîê Funci√≥n para validar webhook secret de Pipefy
def validate_pipefy_webhook_signature(payload_body: bytes, signature: str, secret: str) -> bool:
    """
    Valida la firma del webhook de Pipefy usando HMAC-SHA256.
    
    Args:
        payload_body: Cuerpo raw del webhook en bytes
        signature: Firma recibida en el header X-Pipefy-Signature
        secret: Secret configurado en Pipefy
    
    Returns:
        bool: True si la firma es v√°lida, False en caso contrario
    """
    if not secret:
        logger.warning("‚ö†Ô∏è PIPEFY_WEBHOOK_SECRET n√£o configurado. Valida√ß√£o de assinatura desabilitada.")
        return True  # Si no hay secret configurado, permitir el webhook
    
    if not signature:
        logger.error("‚ùå Header X-Pipefy-Signature ausente")
        return False
    
    try:
        # Pipefy usa HMAC-SHA256 y env√≠a la firma como hex
        expected_signature = hmac.new(
            secret.encode('utf-8'),
            payload_body,
            hashlib.sha256
        ).hexdigest()
        
        # Comparar de forma segura
        is_valid = hmac.compare_digest(signature, expected_signature)
        
        if is_valid:
            logger.info("‚úÖ Assinatura do webhook Pipefy validada com sucesso")
        else:
            logger.error(f"‚ùå Assinatura inv√°lida. Esperado: {expected_signature[:10]}..., Recebido: {signature[:10]}...")
        
        return is_valid
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao validar assinatura do webhook: {e}")
        return False

# üîç Funci√≥n para detectar autom√°ticamente el field_id de Pipefy
async def get_pipefy_field_id_for_informe_crewai(card_id: str) -> Optional[str]:
    """
    Detecta autom√°ticamente el field_id del campo 'Informe CrewAI' en Pipefy.
    MEJORADO: Maneja el comportamiento espec√≠fico de Pipefy donde los campos
    solo aparecen en la API cuando tienen alg√∫n valor asignado.
    
    Args:
        card_id: ID del card de Pipefy
    
    Returns:
        str: field_id si se encuentra, None en caso contrario
    """
    if not PIPEFY_TOKEN:
        logger.error("ERRO: Token Pipefy n√£o configurado.")
        return None
    
    query = """
    query GetCardFields($cardId: ID!) {
        card(id: $cardId) {
            id
            title
            current_phase {
                id
                name
            }
            fields {
                field {
                    id
                    label
                    type
                }
                name
                value
            }
        }
    }
    """
    
    variables = {"cardId": card_id}
    headers = {
        "Authorization": f"Bearer {PIPEFY_TOKEN}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "query": query,
        "variables": variables
    }
    
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post("https://api.pipefy.com/graphql", json=payload, headers=headers)
            response.raise_for_status()
            data = response.json()
            
            if "errors" in data:
                logger.error(f"ERRO GraphQL ao buscar campos: {data['errors']}")
                return None
            
            card_data = data.get("data", {}).get("card")
            if not card_data:
                logger.warning(f"Card {card_id} n√£o encontrado.")
                return None
            
            # Obtener informaci√≥n de la fase actual
            current_phase = card_data.get("current_phase", {})
            phase_id = current_phase.get("id")
            phase_name = current_phase.get("name", "Desconhecida")
            
            logger.info(f"üìç Card {card_id} est√° na fase: {phase_name} (ID: {phase_id})")
            
            fields = card_data.get("fields", [])
            logger.info(f"üìã Total de campos encontrados: {len(fields)}")
            
            # Buscar por nome exato "Informe CrewAI"
            for field in fields:
                field_info = field.get("field", {})
                field_label = field_info.get("label", "").strip()
                field_name = field.get("name", "").strip()
                
                # Verificar coincidencia exacta con "Informe CrewAI"
                if field_label == "Informe CrewAI" or field_name == "Informe CrewAI":
                    field_id = field_info.get("id")
                    logger.info(f"‚úÖ Campo 'Informe CrewAI' encontrado: ID {field_id}")
                    logger.info(f"   - Label: '{field_label}'")
                    logger.info(f"   - Name: '{field_name}'")
                    logger.info(f"   - Type: {field_info.get('type')}")
                    return field_id
            
            # Si no se encuentra con nombre exacto, buscar por palabras clave
            target_keywords = [
                "informe crewai",
                "informe crew ai", 
                "crewai informe",
                "crew ai informe"
            ]
            
            for field in fields:
                field_info = field.get("field", {})
                field_label = field_info.get("label", "").lower()
                field_name = field.get("name", "").lower()
                
                for keyword in target_keywords:
                    if keyword in field_label or keyword in field_name:
                        field_id = field_info.get("id")
                        logger.info(f"‚úÖ Campo encontrado por keyword '{keyword}': ID {field_id}")
                        logger.info(f"   - Label: '{field_info.get('label')}'")
                        logger.info(f"   - Name: '{field.get('name')}'")
                        return field_id
            
            # COMPORTAMIENTO ESPEC√çFICO DE PIPEFY: Los campos sin valor no aparecen en la API
            logger.warning(f"‚ö†Ô∏è Campo 'Informe CrewAI' n√£o encontrado no card {card_id}")
            logger.warning(f"üîç IMPORTANTE: En Pipefy, los campos solo aparecen en la API cuando tienen alg√∫n valor")
            logger.info(f"üìã Campos disponibles en el card (solo los que tienen valor):")
            for field in fields:
                field_info = field.get("field", {})
                field_value = field.get("value", "")
                logger.info(f"   - '{field.get('name')}' (Label: '{field_info.get('label')}', ID: {field_info.get('id')}, Value: '{field_value[:50]}...')")
            
            # Retornar informaci√≥n de la fase para crear el campo si es necesario
            return {"phase_id": phase_id, "phase_name": phase_name, "field_not_found": True}
            
    except Exception as e:
        logger.error(f"ERRO ao buscar field_id para card {card_id}: {e}")
        return None

# üÜï Funci√≥n para crear campo "Informe CrewAI" en una fase espec√≠fica
async def create_informe_crewai_field_in_phase(phase_id: str) -> Optional[str]:
    """
    Crea el campo 'Informe CrewAI' en una fase espec√≠fica de Pipefy.
    
    Args:
        phase_id: ID de la fase donde crear el campo
    
    Returns:
        str: field_id del campo creado, None si falla
    """
    if not PIPEFY_TOKEN:
        logger.error("ERRO: Token Pipefy n√£o configurado.")
        return None
    
    mutation = """
    mutation CreateInformeCrewAIField($phaseId: ID!) {
        createPhaseField(input: {
            phase_id: $phaseId,
            type: "long_text",
            label: "Informe CrewAI",
            description: "Informe generado autom√°ticamente por CrewAI con an√°lisis de documentos",
            required: false,
            editable: true
        }) {
            phase_field {
                id
                label
                type
                description
            }
        }
    }
    """
    
    variables = {"phaseId": phase_id}
    headers = {
        "Authorization": f"Bearer {PIPEFY_TOKEN}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "query": mutation,
        "variables": variables
    }
    
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post("https://api.pipefy.com/graphql", json=payload, headers=headers)
            response.raise_for_status()
            data = response.json()
            
            if "errors" in data:
                logger.error(f"ERRO GraphQL ao criar campo: {data['errors']}")
                return None
            
            result = data.get("data", {}).get("createPhaseField", {})
            phase_field = result.get("phase_field", {})
            
            if phase_field and phase_field.get("id"):
                field_id = phase_field.get("id")
                logger.info(f"‚úÖ Campo 'Informe CrewAI' criado com sucesso!")
                logger.info(f"   - Field ID: {field_id}")
                logger.info(f"   - Label: {phase_field.get('label')}")
                logger.info(f"   - Type: {phase_field.get('type')}")
                logger.info(f"   - Phase ID: {phase_id}")
                return field_id
            else:
                logger.error(f"‚ùå Resposta inesperada ao criar campo: {result}")
                return None
                
    except Exception as e:
        logger.error(f"‚ùå Erro ao criar campo 'Informe CrewAI' na fase {phase_id}: {e}")
        return None

# üîÑ Funci√≥n para asignar valor inicial al campo reci√©n creado
async def initialize_field_with_placeholder(card_id: str, field_id: str) -> bool:
    """
    Asigna un valor inicial al campo para que aparezca en futuras consultas de la API.
    Esto es necesario debido al comportamiento espec√≠fico de Pipefy.
    
    Args:
        card_id: ID del card
        field_id: ID del campo a inicializar
    
    Returns:
        bool: True si la inicializaci√≥n fue exitosa
    """
    placeholder_value = "üîÑ Inicializando campo... El informe se actualizar√° autom√°ticamente."
    
    mutation = """
    mutation {
        updateCardField(input: {card_id: %s, field_id: "%s", new_value: "%s"}) {
            card {
                id
                title
            }
        }
    }
    """ % (card_id, field_id, placeholder_value)
    
    headers = {
        "Authorization": f"Bearer {PIPEFY_TOKEN}",
        "Content-Type": "application/json"
    }
    
    payload = {"query": mutation}
    
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post("https://api.pipefy.com/graphql", json=payload, headers=headers)
            response.raise_for_status()
            data = response.json()
            
            if "errors" in data:
                logger.error(f"ERRO ao inicializar campo: {data['errors']}")
                return False
            
            result = data.get("data", {}).get("updateCardField", {})
            if result and result.get("card"):
                logger.info(f"‚úÖ Campo inicializado com placeholder para aparecer na API")
                return True
            else:
                logger.error(f"‚ùå Falha ao inicializar campo com placeholder")
                return False
                
    except Exception as e:
        logger.error(f"‚ùå Erro ao inicializar campo: {e}")
        return False

# üìù Funci√≥n para actualizar campo espec√≠fico en Pipefy (VERSI√ìN DEFINITIVA CON FIELD_ID FIJO)
async def update_pipefy_informe_crewai_field(card_id: str, informe_content: str) -> bool:
    """
    Actualiza el campo 'Informe CrewAI' en Pipefy usando el field_id fijo descubierto.
    
    SOLUCI√ìN DEFINITIVA:
    - Field ID fijo: "informe_crewai_2" (descubierto mediante query pipe.start_form_fields)
    - Sintaxis oficial: updateCardField con card_id, field_id, new_value
    - Sin b√∫squedas din√°micas ni creaci√≥n de campos
    
    Args:
        card_id: ID del card de Pipefy
        informe_content: Contenido del informe a actualizar
    
    Returns:
        bool: True si la actualizaci√≥n fue exitosa, False en caso contrario
    """
    try:
        logger.info(f"üîÑ Actualizando campo 'Informe CrewAI' para card: {card_id}")
        logger.info(f"üìù Field ID fijo: informe_crewai_2")
        
        # Field ID fijo descubierto por el usuario
        field_id = "informe_crewai_2"
        
        # Escapar contenido para GraphQL
        escaped_content = informe_content.replace('"', '\\"').replace('\n', '\\n').replace('\r', '')
        
        # Sintaxis oficial de Pipefy
        mutation = """
        mutation {
            updateCardField(input: {card_id: %s, field_id: "%s", new_value: "%s"}) {
                card {
                    id
                    title
                }
            }
        }
        """ % (card_id, field_id, escaped_content)
        
        headers = {
            "Authorization": f"Bearer {PIPEFY_TOKEN}",
            "Content-Type": "application/json"
        }
        
        payload = {"query": mutation}
        
        async with httpx.AsyncClient() as client:
            response = await client.post("https://api.pipefy.com/graphql", json=payload, headers=headers)
            response.raise_for_status()
            data = response.json()
            
            if "errors" in data:
                logger.error(f"‚ùå Erro GraphQL ao atualizar campo: {data['errors']}")
                return False
            
            result = data.get("data", {}).get("updateCardField", {})
            card_info = result.get("card", {})
            
            if card_info and card_info.get("id"):
                logger.info(f"‚úÖ Campo 'Informe CrewAI' atualizado com sucesso!")
                logger.info(f"   - Card ID: {card_info.get('id')}")
                logger.info(f"   - Card Title: {card_info.get('title')}")
                logger.info(f"   - Field ID: {field_id}")
                logger.info(f"   - Conte√∫do: {informe_content[:100]}...")
                logger.info(f"   - Estrat√©gia: Field ID fijo + sintaxis oficial")
                return True
            else:
                logger.error(f"‚ùå Resposta inesperada da muta√ß√£o: {result}")
                return False
                
    except Exception as e:
        logger.error(f"‚ùå Erro ao atualizar campo 'Informe CrewAI': {e}")
        return False

# Funciones auxiliares (iguales al original)
async def get_pipefy_card_attachments(card_id: str) -> List[PipefyAttachment]:
    """Obt√©m anexos de um card do Pipefy via GraphQL."""
    if not PIPEFY_TOKEN:
        logger.error("ERRO: Token Pipefy n√£o configurado.")
        return []
    
    query = """
    query GetCardAttachments($cardId: ID!) {
        card(id: $cardId) {
            id
            title
            fields {
                name
                value
            }
        }
    }
    """
    
    variables = {"cardId": card_id}
    headers = {
        "Authorization": f"Bearer {PIPEFY_TOKEN}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "query": query,
        "variables": variables
    }
    
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post("https://api.pipefy.com/graphql", json=payload, headers=headers)
            response.raise_for_status()
            data = response.json()
            
            if "errors" in data:
                logger.error(f"ERRO GraphQL Pipefy: {data['errors']}")
                return []
            
            card_data = data.get("data", {}).get("card")
            if not card_data:
                logger.warning(f"ALERTA: Card {card_id} n√£o encontrado ou sem dados.")
                return []
            
            attachments = []
            fields = card_data.get("fields", [])
            
            for field in fields:
                field_value = field.get("value", "")
                if field_value and isinstance(field_value, str):
                    try:
                        import json
                        urls = json.loads(field_value)
                        if isinstance(urls, list):
                            for url in urls:
                                if isinstance(url, str) and url.startswith("http"):
                                    filename = url.split("/")[-1].split("?")[0]
                                    if not filename or filename == "":
                                        filename = f"{field.get('name', 'documento')}.pdf"
                                    
                                    attachments.append(PipefyAttachment(
                                        name=filename,
                                        path=url
                                    ))
                    except (json.JSONDecodeError, TypeError):
                        if field_value.startswith("http"):
                            filename = field_value.split("/")[-1].split("?")[0]
                            if not filename or filename == "":
                                filename = f"{field.get('name', 'documento')}.pdf"
                            
                            attachments.append(PipefyAttachment(
                                name=filename,
                                path=field_value
                            ))
            
            logger.info(f"INFO: {len(attachments)} anexos encontrados para card {card_id}.")
            return attachments
            
    except Exception as e:
        logger.error(f"ERRO ao buscar anexos do card {card_id}: {e}")
        return []

async def download_file_to_temp(url: str, original_filename: str) -> Optional[str]:
    """Baixa um arquivo de uma URL para um arquivo tempor√°rio."""
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(url)
            response.raise_for_status()
            
            with tempfile.NamedTemporaryFile(delete=False, suffix=f"_{original_filename}") as temp_file:
                temp_file.write(response.content)
                temp_file_path = temp_file.name
            
            logger.info(f"INFO: Arquivo '{original_filename}' baixado para: {temp_file_path}")
            return temp_file_path
            
    except Exception as e:
        logger.error(f"ERRO ao baixar arquivo '{original_filename}' de {url}: {e}")
        return None

async def upload_to_supabase_storage_async(local_file_path: str, case_id: str, original_filename: str) -> Optional[str]:
    """Faz upload de um arquivo local para o Supabase Storage."""
    if not supabase_client:
        logger.error("ERRO: Cliente Supabase n√£o inicializado.")
        return None
    
    try:
        storage_path = f"{case_id}/{original_filename}"
        
        def sync_upload_and_get_url():
            with open(local_file_path, 'rb') as file:
                upload_response = supabase_client.storage.from_(SUPABASE_STORAGE_BUCKET_NAME).upload(
                    storage_path, file, file_options={"upsert": "true"}
                )
                
                if hasattr(upload_response, 'error') and upload_response.error:
                    raise Exception(f"Erro no upload: {upload_response.error}")
                
                public_url_response = supabase_client.storage.from_(SUPABASE_STORAGE_BUCKET_NAME).get_public_url(storage_path)
                return public_url_response
        
        public_url = await asyncio.to_thread(sync_upload_and_get_url)
        
        # Limpar arquivo tempor√°rio
        try:
            os.unlink(local_file_path)
        except:
            pass
        
        logger.info(f"INFO: Upload conclu√≠do para '{original_filename}'. URL: {public_url}")
        return public_url
        
    except Exception as e:
        logger.error(f"ERRO no upload de '{original_filename}': {e}")
        try:
            os.unlink(local_file_path)
        except:
            pass
        return None

async def determine_document_tag(filename: str, card_fields: Optional[List[Dict]] = None) -> str:
    """Determina a tag do documento baseada no nome do arquivo."""
    filename_lower = filename.lower()
    
    tag_keywords = {
        "contrato_social": ["contrato", "social", "estatuto"],
        "comprovante_residencia": ["comprovante", "residencia", "endereco"],
        "documento_identidade": ["rg", "identidade", "cnh"],
        "declaracao_impostos": ["declaracao", "imposto", "ir"],
        "certificado_registro": ["certificado", "registro"],
        "procuracao": ["procuracao"],
        "balanco_patrimonial": ["balanco", "patrimonial", "demonstracao"],
        "faturamento": ["faturamento", "receita"]
    }
    
    for tag, keywords in tag_keywords.items():
        if any(keyword in filename_lower for keyword in keywords):
            return tag
    
    return "outro_documento"

async def register_document_in_db(case_id: str, document_name: str, document_tag: str, file_url: str, pipe_id: Optional[str] = None):
    """Registra um documento na tabela 'documents' do Supabase."""
    if not supabase_client:
        logger.error("ERRO: Cliente Supabase n√£o inicializado.")
        return False
    
    try:
        data_to_insert = {
            "case_id": case_id,
            "name": document_name,
            "document_tag": document_tag,
            "file_url": file_url,
            "status": "uploaded"
        }
        
        if pipe_id:
            data_to_insert["pipe_id"] = pipe_id
            logger.info(f"INFO: Registrando documento con pipe_id: {pipe_id}")
        
        response = await asyncio.to_thread(
            supabase_client.table("documents").upsert(data_to_insert, on_conflict="case_id, name").execute
        )
        
        if hasattr(response, 'error') and response.error:
            logger.error(f"ERRO Supabase DB (upsert) para {document_name}: {response.error.message}")
            return False
        if response.data:
            logger.info(f"INFO: Documento '{document_name}' registrado/atualizado no DB para case_id '{case_id}'.")
            return True
        logger.warning(f"AVISO: Upsert do documento '{document_name}' no DB n√£o retornou dados nem erro expl√≠cito.")
        return False
    except Exception as e:
        logger.error(f"ERRO ao registrar documento '{document_name}' no Supabase DB: {e}")
        return False

async def get_checklist_url_from_supabase(config_name: str = "checklist_cadastro_pj") -> str:
    """Obt√©m a URL do checklist da tabela checklist_config."""
    if not supabase_client:
        logger.warning("AVISO: Cliente Supabase n√£o inicializado para buscar checklist. Usando URL padr√£o.")
        return "https://aguoqgqbdbyipztgrmbd.supabase.co/storage/v1/object/public/checklist/checklist.pdf"
    
    try:
        logger.info(f"INFO: Buscando URL do checklist '{config_name}' de checklist_config...")
        
        def sync_get_checklist_url():
            return supabase_client.table("checklist_config").select("checklist_url").eq("config_name", config_name).single().execute()
        
        response = await asyncio.to_thread(sync_get_checklist_url)

        if response.data and response.data.get("checklist_url"):
            checklist_url = response.data["checklist_url"]
            logger.info(f"INFO: URL do checklist obtida: {checklist_url}")
            return checklist_url
        else:
            logger.warning(f"AVISO: URL do checklist '{config_name}' n√£o encontrada. Usando URL padr√£o.")
            return "https://aguoqgqbdbyipztgrmbd.supabase.co/storage/v1/object/public/checklist/checklist.pdf"
            
    except Exception as e:
        logger.warning(f"AVISO: Erro ao buscar URL do checklist '{config_name}': {e}. Usando URL padr√£o.")
        return "https://aguoqgqbdbyipztgrmbd.supabase.co/storage/v1/object/public/checklist/checklist.pdf"

# üîó COMUNICACI√ìN HTTP DIRECTA CON CREWAI
async def call_crewai_analysis_service(case_id: str, documents: List[Dict], checklist_url: str, pipe_id: Optional[str] = None) -> Dict[str, Any]:
    """
    Llama directamente al servicio CrewAI para an√°lisis de documentos.
    MANTIENE LA MODULARIDAD: Solo llama al servicio, no guarda en Supabase.
    El m√≥dulo CrewAI se encarga de guardar el informe en la tabla informe_cadastro.
    
    MEJORADO: Maneja cold starts y timeouts de Render.
    """
    try:
        # Preparar payload para CrewAI
        analysis_request = CrewAIAnalysisRequest(
            case_id=case_id,
            documents=documents,
            checklist_url=checklist_url,
            current_date=datetime.now().strftime('%Y-%m-%d'),
            pipe_id=pipe_id
        )
        
        logger.info(f"üîó Llamando al servicio CrewAI para case_id: {case_id}")
        logger.info(f"üìÑ Documentos a analizar: {len(documents)}")
        logger.info(f"üéØ URL CrewAI: {CREWAI_SERVICE_URL}/analyze")
        
        # MEJORADO: Primero verificar que el servicio est√© despierto
        logger.info("üè• Verificando estado del servicio CrewAI...")
        try:
            async with httpx.AsyncClient(timeout=30.0) as health_client:
                health_response = await health_client.get(f"{CREWAI_SERVICE_URL}/health")
                if health_response.status_code == 200:
                    logger.info("‚úÖ Servicio CrewAI est√° activo")
                else:
                    logger.warning(f"‚ö†Ô∏è Servicio CrewAI respondi√≥ con status: {health_response.status_code}")
        except Exception as health_error:
            logger.warning(f"‚ö†Ô∏è No se pudo verificar estado del servicio: {health_error}")
        
        # Llamada HTTP directa al servicio CrewAI con timeout extendido para cold starts
        logger.info("üöÄ Iniciando an√°lisis CrewAI (puede tardar si el servicio estaba dormido)...")
        
        # TIMEOUT AUMENTADO: 15 minutos para manejar cold starts + an√°lisis completo
        async with httpx.AsyncClient(timeout=900.0) as client:  
            response = await client.post(
                f"{CREWAI_SERVICE_URL}/analyze",
                json=analysis_request.model_dump()
            )
            
            if response.status_code == 200:
                result = response.json()
                logger.info(f"‚úÖ An√°lisis CrewAI completado exitosamente para case_id: {case_id}")
                
                # Procesar resultado completo
                if result.get("status") == "completed" and "analysis_result" in result:
                    analysis_result = result["analysis_result"]
                    summary_report = analysis_result.get("summary_report", "")
                    
                    # MODULARIDAD: Solo el m√≥dulo CrewAI guarda en Supabase
                    # Este m√≥dulo solo se encarga de la comunicaci√≥n con Pipefy
                    logger.info(f"üíæ Informe guardado por m√≥dulo CrewAI en tabla informe_cadastro")
                    
                    # üÜï NUEVA L√ìGICA: Verificar si hay respuesta JSON estructurada para orquestaci√≥n
                    structured_response = analysis_result.get("structured_response")
                    if structured_response and isinstance(structured_response, dict):
                        logger.info(f"üéØ Resposta JSON estruturada detectada - Executando orquestrador")
                        
                        # Executar orquestrador com a resposta estruturada
                        orchestration_result = await handle_crewai_analysis_result(case_id, structured_response)
                        
                        return {
                            "status": "success_with_orchestration",
                            "crewai_response": result,
                            "orchestration_result": orchestration_result,
                            "supabase_saved_by_crewai": True,
                            "communication": "http_direct_sync_with_orchestration",
                            "risk_score": analysis_result.get("risk_score"),
                            "summary_report": summary_report,
                            "architecture": "modular_separation_v2"
                        }
                    else:
                        # L√ìGICA ANTERIOR: Solo actualizar campo Informe CrewAI (compatibilidad)
                        logger.info(f"üìù Resposta n√£o estruturada - Usando l√≥gica anterior")
                        pipefy_updated = False
                        if summary_report:
                            logger.info(f"üìù Actualizando campo 'Informe CrewAI' en Pipefy para case_id: {case_id}")
                            pipefy_updated = await update_pipefy_informe_crewai_field(case_id, summary_report)
                            
                            if pipefy_updated:
                                logger.info(f"‚úÖ Campo 'Informe CrewAI' actualizado exitosamente para case_id: {case_id}")
                            else:
                                logger.warning(f"‚ö†Ô∏è No se pudo actualizar campo 'Informe CrewAI' para case_id: {case_id}")
                        
                        return {
                            "status": "success",
                            "crewai_response": result,
                            "supabase_saved_by_crewai": True,  # Guardado por el m√≥dulo CrewAI
                            "pipefy_updated": pipefy_updated,
                            "communication": "http_direct_sync",
                            "risk_score": analysis_result.get("risk_score"),
                            "summary_report": summary_report,
                            "architecture": "modular_separation"
                        }
                else:
                    logger.warning(f"‚ö†Ô∏è Respuesta CrewAI incompleta para case_id: {case_id}")
                    return {
                        "status": "partial_success",
                        "crewai_response": result,
                        "communication": "http_direct_sync"
                    }
            elif response.status_code == 502:
                logger.error(f"üõå Servicio CrewAI est√° dormido (502 Bad Gateway) - Reintentando en 30 segundos...")
                
                # RETRY PARA COLD STARTS: Esperar y reintentar una vez
                await asyncio.sleep(30)
                logger.info("üîÑ Reintentando llamada a CrewAI despu√©s de cold start...")
                
                async with httpx.AsyncClient(timeout=900.0) as retry_client:
                    retry_response = await retry_client.post(
                        f"{CREWAI_SERVICE_URL}/analyze",
                        json=analysis_request.model_dump()
                    )
                    
                    if retry_response.status_code == 200:
                        result = retry_response.json()
                        logger.info(f"‚úÖ An√°lisis CrewAI completado exitosamente en reintento para case_id: {case_id}")
                        
                        if result.get("status") == "completed" and "analysis_result" in result:
                            analysis_result = result["analysis_result"]
                            summary_report = analysis_result.get("summary_report", "")
                            
                            logger.info(f"üíæ Informe guardado por m√≥dulo CrewAI en tabla informe_cadastro")
                            
                            # üÜï NUEVA L√ìGICA: Verificar si hay respuesta JSON estructurada para orquestaci√≥n (retry)
                            structured_response = analysis_result.get("structured_response")
                            if structured_response and isinstance(structured_response, dict):
                                logger.info(f"üéØ Resposta JSON estruturada detectada no retry - Executando orquestrador")
                                
                                # Executar orquestrador com a resposta estruturada
                                orchestration_result = await handle_crewai_analysis_result(case_id, structured_response)
                                
                                return {
                                    "status": "success_after_retry_with_orchestration",
                                    "crewai_response": result,
                                    "orchestration_result": orchestration_result,
                                    "supabase_saved_by_crewai": True,
                                    "communication": "http_direct_sync_retry_with_orchestration",
                                    "risk_score": analysis_result.get("risk_score"),
                                    "summary_report": summary_report,
                                    "architecture": "modular_separation_v2",
                                    "cold_start_handled": True
                                }
                            else:
                                # L√ìGICA ANTERIOR: Solo actualizar campo Informe CrewAI (compatibilidad retry)
                                logger.info(f"üìù Resposta n√£o estruturada no retry - Usando l√≥gica anterior")
                                pipefy_updated = False
                                if summary_report:
                                    logger.info(f"üìù Actualizando campo 'Informe CrewAI' en Pipefy para case_id: {case_id}")
                                    pipefy_updated = await update_pipefy_informe_crewai_field(case_id, summary_report)
                                
                                return {
                                    "status": "success_after_retry",
                                    "crewai_response": result,
                                    "supabase_saved_by_crewai": True,
                                    "pipefy_updated": pipefy_updated,
                                    "communication": "http_direct_sync_retry",
                                    "risk_score": analysis_result.get("risk_score"),
                                    "summary_report": summary_report,
                                    "architecture": "modular_separation",
                                    "cold_start_handled": True
                                }
                    
                    logger.error(f"‚ùå Reintento fall√≥: {retry_response.status_code} - {retry_response.text}")
                    return {
                        "status": "error_after_retry",
                        "error": f"CrewAI service error after retry: {retry_response.status_code}",
                        "details": retry_response.text,
                        "communication": "http_direct_sync_retry_failed"
                    }
            else:
                logger.error(f"‚ùå Error en servicio CrewAI: {response.status_code} - {response.text}")
                return {
                    "status": "error",
                    "error": f"CrewAI service error: {response.status_code}",
                    "details": response.text,
                    "communication": "http_direct_sync"
                }
                
    except httpx.TimeoutException:
        logger.error(f"‚è∞ Timeout al llamar al servicio CrewAI para case_id: {case_id}")
        logger.error("üí° Esto puede indicar que el servicio est√° en cold start. Considera usar el endpoint as√≠ncrono.")
        return {
            "status": "timeout",
            "error": "CrewAI service timeout - posible cold start",
            "communication": "http_direct_sync",
            "suggestion": "El servicio puede estar dormido. Reintenta en unos minutos."
        }
    except Exception as e:
        logger.error(f"‚ùå Error al llamar al servicio CrewAI: {e}")
        return {
            "status": "error",
            "error": str(e),
            "communication": "http_direct_sync"
        }

# üÜï FUNCIONES DE INTEGRACI√ìN SEG√öN PRD

async def get_card_current_phase_info(card_id: str) -> Optional[dict]:
    """
    Obtiene informaci√≥n de la fase actual del card para diagn√≥stico.
    
    Args:
        card_id: ID del card
        
    Returns:
        dict: Informaci√≥n de la fase actual con id y name, o None si hay error
    """
    if not PIPEFY_TOKEN:
        logger.error("‚ùå Token Pipefy n√£o configurado")
        return None
    
    query = """
    query GetCardCurrentPhase($cardId: ID!) {
        card(id: $cardId) {
            id
            title
            current_phase {
                id
                name
            }
        }
    }
    """
    
    variables = {"cardId": card_id}
    headers = {
        "Authorization": f"Bearer {PIPEFY_TOKEN}",
        "Content-Type": "application/json"
    }
    
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(PIPEFY_API_URL, json={"query": query, "variables": variables}, headers=headers)
            
            if response.status_code == 200:
                data = response.json()
                if "errors" not in data and data.get("data", {}).get("card"):
                    card_data = data["data"]["card"]
                    phase_info = card_data.get("current_phase", {})
                    return {
                        "id": phase_info.get("id"),
                        "name": phase_info.get("name"),
                        "card_title": card_data.get("title")
                    }
                else:
                    logger.error(f"‚ùå Erro GraphQL ao obter fase atual: {data.get('errors', 'Unknown error')}")
            else:
                logger.error(f"‚ùå HTTP {response.status_code} ao obter fase atual do card")
                
    except Exception as e:
        logger.error(f"‚ùå Exce√ß√£o ao obter fase atual: {str(e)}")
    
    return None


async def move_pipefy_card_to_phase(card_id: str, phase_id: str) -> bool:
    """
    Mueve un card de Pipefy a una nueva fase usando la API GraphQL.
    ACTUALIZADO seg√∫n documentaci√≥n oficial de Pipefy.
    
    Args:
        card_id: ID del card a mover
        phase_id: ID de la fase destino
    
    Returns:
        bool: True si el movimiento fue exitoso, False en caso contrario
    """
    if not PIPEFY_TOKEN:
        logger.error("‚ùå Token Pipefy n√£o configurado para mover card")
        return False
    
    # PASO 1: Obtener informaci√≥n de la fase actual para diagn√≥stico
    current_phase_info = await get_card_current_phase_info(card_id)
    if current_phase_info:
        logger.info(f"üìç DIAGN√ìSTICO DE MOVIMIENTO:")
        logger.info(f"   üéØ Card: {card_id} - '{current_phase_info.get('card_title', 'Sin t√≠tulo')}'")
        logger.info(f"   üìç Fase ACTUAL: {current_phase_info.get('name')} (ID: {current_phase_info.get('id')})")
        logger.info(f"   üìç Fase DESTINO: {phase_id}")
        
        # Verificar si ya est√° en la fase destino
        if current_phase_info.get('id') == phase_id:
            logger.info(f"‚úÖ Card ya est√° en la fase destino {phase_id}")
            return True
    else:
        logger.warning(f"‚ö†Ô∏è No se pudo obtener informaci√≥n de la fase actual para card {card_id}")
    
    # PASO 2: GraphQL mutation seg√∫n documentaci√≥n oficial de Pipefy
    # Formato simplificado sin variables para evitar errores de sintaxis
    mutation = f"""
    mutation {{
        moveCardToPhase(input: {{
            card_id: {card_id}
            destination_phase_id: {phase_id}
        }}) {{
            card {{
                id
                current_phase {{
                    id
                    name
                }}
            }}
        }}
    }}
    """
    
    headers = {
        "Authorization": f"Bearer {PIPEFY_TOKEN}",
        "Content-Type": "application/json"
    }
    
    payload = {"query": mutation}
    
    try:
        logger.info(f"üîÑ Ejecutando movimiento de card...")
        logger.info(f"üîç Payload GraphQL: {json.dumps(payload, indent=2)}")
        
        async with httpx.AsyncClient() as client:
            response = await client.post(PIPEFY_API_URL, json=payload, headers=headers)
            logger.info(f"üìä HTTP Status: {response.status_code}")
            
            response.raise_for_status()
            data = response.json()
            logger.info(f"üìÑ Response Data: {json.dumps(data, indent=2)}")
            
            if "errors" in data:
                logger.error(f"‚ùå Erro GraphQL ao mover card {card_id}: {data['errors']}")
                for error in data['errors']:
                    error_msg = error.get('message', 'Unknown error')
                    error_code = error.get('extensions', {}).get('code', 'Unknown code')
                    logger.error(f"   - {error_code}: {error_msg}")
                    
                    # Mensaje espec√≠fico para errores de restricci√≥n de fase
                    if "Cannot move" in error_msg or "PHASE_TRANSITION_ERROR" in error_code:
                        logger.error(f"üö® FASE RESTRICTION ERROR: La fase destino {phase_id} no permite el movimiento desde la fase actual")
                        logger.error(f"üí° SOLUCI√ìN: Verificar 'Move card settings' en la UI de Pipefy para esta fase")
                        
                return False
            
            move_result = data.get("data", {}).get("moveCardToPhase")
            if move_result and move_result.get("card"):
                new_phase = move_result["card"]["current_phase"]
                logger.info(f"‚úÖ Card {card_id} movido exitosamente!")
                logger.info(f"   üìç Nueva fase: {new_phase['name']} (ID: {new_phase['id']})")
                return True
            else:
                logger.error(f"‚ùå Resposta inesperada ao mover card {card_id}: {data}")
                return False
                
    except Exception as e:
        logger.error(f"‚ùå Erro ao mover card {card_id} para fase {phase_id}: {e}")
        logger.error(f"üìç Erro completo: {type(e).__name__}: {str(e)}")
        return False

async def get_manager_phone_for_card(card_id: str) -> Optional[str]:
    """
    Obt√©m o n√∫mero de telefone do gestor comercial respons√°vel pelo card.
    Por enquanto retorna um n√∫mero fixo para testes, pero puede ser expandido
    para buscar em campos do card ou base de dados.
    
    Args:
        card_id: ID do card
    
    Returns:
        str: N√∫mero de telefone do gestor ou None se n√£o encontrado
    """
    # TODO: Implementar l√≥gica para buscar o telefone real do gestor
    # Pode ser um campo no card ou uma consulta √† base de dados
    
    # Por enquanto, usar n√∫mero de teste
    test_manager_phone = "+5531999999999"  # Substituir por l√≥gica real
    
    logger.info(f"üìû N√∫mero do gestor para card {card_id}: {test_manager_phone}")
    return test_manager_phone

async def send_whatsapp_notification(card_id: str, relatorio_detalhado: str) -> bool:
    """
    Envia notifica√ß√£o via WhatsApp usando Twilio para pend√™ncias bloqueantes.
    MELHORADO com diagn√≥stico de credenciais.
    
    Args:
        card_id: ID do card com pend√™ncia
        relatorio_detalhado: Relat√≥rio detalhado da pend√™ncia
    
    Returns:
        bool: True se a notifica√ß√£o foi enviada com sucesso
    """
    # Verificar credenciais Twilio com diagn√≥stico detalhado
    if not TWILIO_ACCOUNT_SID or not TWILIO_AUTH_TOKEN:
        logger.error("‚ùå Credenciais Twilio n√£o configuradas")
        logger.error(f"   üìä TWILIO_ACCOUNT_SID configurado: {'‚úÖ Sim' if TWILIO_ACCOUNT_SID else '‚ùå N√£o'}")
        logger.error(f"   üìä TWILIO_AUTH_TOKEN configurado: {'‚úÖ Sim' if TWILIO_AUTH_TOKEN else '‚ùå N√£o'}")
        logger.error(f"   üìä TWILIO_WHATSAPP_NUMBER configurado: {'‚úÖ Sim' if TWILIO_WHATSAPP_NUMBER else '‚ùå N√£o'}")
        return False
    
    if not TWILIO_WHATSAPP_NUMBER:
        logger.error("‚ùå TWILIO_WHATSAPP_NUMBER n√£o configurado")
        return False
    
    try:
        # Importar Twilio apenas quando necess√°rio
        from twilio.rest import Client
        
        # Obter n√∫mero do gestor
        manager_phone = await get_manager_phone_for_card(card_id)
        if not manager_phone:
            logger.error(f"‚ùå N√∫mero do gestor n√£o encontrado para card {card_id}")
            return False
        
        # Log de diagn√≥stico de credenciais mascaradas
        logger.info(f"üìä DIAGN√ìSTICO TWILIO:")
        logger.info(f"   üìû Account SID: {TWILIO_ACCOUNT_SID[:8]}...{TWILIO_ACCOUNT_SID[-4:] if len(TWILIO_ACCOUNT_SID) > 8 else TWILIO_ACCOUNT_SID}")
        logger.info(f"   üîë Auth Token: {TWILIO_AUTH_TOKEN[:8]}...{TWILIO_AUTH_TOKEN[-4:] if len(TWILIO_AUTH_TOKEN) > 8 else TWILIO_AUTH_TOKEN}")
        logger.info(f"   üì± WhatsApp Number: {TWILIO_WHATSAPP_NUMBER}")
        logger.info(f"   üì± Destinat√°rio: {manager_phone}")
        
        # Criar cliente Twilio
        client = Client(TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN)
        
        # Preparar mensagem
        message_body = (
            f"üö® *Pend√™ncia Cr√≠tica no Pipefy!*\n\n"
            f"üìã Card: https://app.pipefy.com/open-cards/{card_id}\n\n"
            f"üìÑ *Resumo da Pend√™ncia:*\n{relatorio_detalhado[:300]}...\n\n"
            f"‚ö° *A√ß√£o Necess√°ria:* Verifique o card para detalhes e providencie a documenta√ß√£o necess√°ria.\n\n"
            f"ü§ñ Mensagem autom√°tica do sistema de triagem documental."
        )
        
        # Enviar mensagem
        message = client.messages.create(
            from_=f"whatsapp:{TWILIO_WHATSAPP_NUMBER}",
            body=message_body,
            to=f"whatsapp:{manager_phone}"
        )
        
        logger.info(f"‚úÖ Notifica√ß√£o WhatsApp enviada com sucesso para {manager_phone}")
        logger.info(f"üì± SID da mensagem: {message.sid}")
        return True
        
    except ImportError:
        logger.error("‚ùå Biblioteca Twilio n√£o instalada. Execute: pip install twilio")
        return False
    except Exception as e:
        logger.error(f"‚ùå Erro ao enviar notifica√ß√£o WhatsApp: {e}")
        logger.error(f"   üìä Tipo do erro: {type(e).__name__}")
        logger.error(f"   üìä Detalhes: {str(e)}")
        
        # Diagn√≥stico espec√≠fico para erros de autentica√ß√£o
        if "401" in str(e) or "Authenticate" in str(e):
            logger.error("üö® ERRO DE AUTENTICA√á√ÉO TWILIO:")
            logger.error("   üí° Verifique se as credenciais est√£o corretas no ambiente Render")
            logger.error("   üí° Account SID deve come√ßar com 'AC'")
            logger.error("   üí° Auth Token deve ter 32 caracteres")
            
        return False

async def extract_cnpj_from_pipefy_card(card_id: str) -> Optional[str]:
    """
    Extrae CNPJ de los campos del card de Pipefy como fallback.
    
    Args:
        card_id: ID del card de Pipefy
        
    Returns:
        str: CNPJ encontrado (solo d√≠gitos) o None si no se encuentra
    """
    if not PIPEFY_TOKEN:
        logger.error("Token Pipefy n√£o configurado para extrair CNPJ do card")
        return None
    
    query = """
    query GetCardFields($cardId: ID!) {
        card(id: $cardId) {
            id
            title
            fields {
                field {
                    id
                    label
                    type
                }
                value
            }
        }
    }
    """
    
    variables = {"cardId": card_id}
    headers = {
        "Authorization": f"Bearer {PIPEFY_TOKEN}",
        "Content-Type": "application/json"
    }
    payload = {"query": query, "variables": variables}
    
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(PIPEFY_API_URL, json=payload, headers=headers)
            response.raise_for_status()
            data = response.json()
            
            if "errors" in data:
                logger.error(f"‚ùå Erro GraphQL ao obter campos do card: {data['errors']}")
                return None
            
            card_data = data.get("data", {}).get("card")
            if not card_data:
                logger.warning(f"Card {card_id} n√£o encontrado")
                return None
            
            # Buscar CNPJ nos campos do card
            import re
            cnpj_patterns_card = [
                r'\b\d{2}[\.\s]?\d{3}[\.\s]?\d{3}[\/\s]?\d{4}[\-\s]?\d{2}\b',
                r'\b\d{14}\b',
                r'CNPJ[:\s]*\d{2}[\.\s]?\d{3}[\.\s]?\d{3}[\/\s]?\d{4}[\-\s]?\d{2}',
                r'CNPJ[:\s]*\d{14}'
            ]
            
            # Buscar en todos os campos
            search_text = f"{card_data.get('title', '')} "
            for field_data in card_data.get('fields', []):
                field_info = field_data.get('field', {})
                field_label = field_info.get('label', '')
                field_value = field_data.get('value', '')
                
                if field_value:
                    search_text += f"{field_label}: {field_value} "
            
            logger.info(f"üîç Buscando CNPJ nos campos do card: {search_text[:200]}...")
            
            for pattern in cnpj_patterns_card:
                cnpj_matches = re.findall(pattern, search_text, re.IGNORECASE)
                if cnpj_matches:
                    raw_cnpj = cnpj_matches[0]
                    if 'CNPJ' in raw_cnpj.upper():
                        raw_cnpj = re.sub(r'CNPJ[:\s]*', '', raw_cnpj, flags=re.IGNORECASE)
                    
                    cnpj_clean = re.sub(r'[^\d]', '', raw_cnpj)
                    if len(cnpj_clean) == 14:
                        logger.info(f"‚úÖ CNPJ extra√≠do do card: {cnpj_clean}")
                        return cnpj_clean
            
            logger.warning(f"‚ùå Nenhum CNPJ v√°lido encontrado nos campos do card {card_id}")
            return None
            
    except Exception as e:
        logger.error(f"‚ùå Erro ao extrair CNPJ do card {card_id}: {e}")
        return None

async def gerar_e_armazenar_cartao_cnpj(case_id: str, cnpj: str) -> bool:
    """
    Gera Cart√£o CNPJ via API CNPJ√° e armazena no Supabase Storage.
    
    Args:
        case_id: ID do caso
        cnpj: CNPJ para gerar o cart√£o
    
    Returns:
        bool: True se o documento foi gerado e armazenado com sucesso
    """
    if not CNPJA_API_KEY:
        logger.error("‚ùå API Key CNPJ√° n√£o configurada")
        return False
    
    if not supabase_client:
        logger.error("‚ùå Cliente Supabase n√£o inicializado")
        return False
    
    try:
        # Limpar CNPJ (remover caracteres especiais)
        cnpj_clean = ''.join(filter(str.isdigit, cnpj))
        
        if len(cnpj_clean) != 14:
            logger.error(f"‚ùå CNPJ inv√°lido: {cnpj}")
            return False
        
        logger.info(f"üè≠ Gerando Cart√£o CNPJ para {cnpj_clean} no caso {case_id}")
        
        # Chamar API CNPJ√°
        headers = {
            'Authorization': f'Bearer {CNPJA_API_KEY}',
            'Content-Type': 'application/json'
        }
        
        url = f'https://api.cnpja.com/rfb/certificate?taxId={cnpj_clean}&pages=REGISTRATION'
        
        async with httpx.AsyncClient(timeout=60.0) as client:
            response = await client.get(url, headers=headers)
            response.raise_for_status()
            
            # Verificar se a resposta √© um PDF
            content_type = response.headers.get('content-type', '')
            if 'application/pdf' not in content_type:
                logger.error(f"‚ùå Resposta da API CNPJ√° n√£o √© um PDF: {content_type}")
                return False
            
            pdf_content = response.content
            logger.info(f"‚úÖ PDF do Cart√£o CNPJ obtido com sucesso ({len(pdf_content)} bytes)")
            
            # Definir caminho no storage
            file_path = f"{case_id}/cartao_cnpj_gerado.pdf"
            
            # Upload para Supabase Storage
            def sync_upload():
                return supabase_client.storage.from_(SUPABASE_STORAGE_BUCKET_NAME).upload(
                    file_path, 
                    pdf_content,
                    file_options={"content-type": "application/pdf"}
                )
            
            upload_result = await asyncio.to_thread(sync_upload)
            
            if upload_result:
                logger.info(f"‚úÖ Cart√£o CNPJ armazenado em: {file_path}")
                
                # Obter URL p√∫blica do arquivo
                def sync_get_public_url():
                    return supabase_client.storage.from_(SUPABASE_STORAGE_BUCKET_NAME).get_public_url(file_path)
                
                public_url = await asyncio.to_thread(sync_get_public_url)
                
                # Registrar documento na base de dados
                await register_document_in_db(
                    case_id=case_id,
                    document_name="cartao_cnpj_gerado.pdf",
                    document_tag="cartao_cnpj",
                    file_url=public_url
                )
                
                logger.info(f"‚úÖ Cart√£o CNPJ gerado e registrado com sucesso para caso {case_id}")
                return True
            else:
                logger.error(f"‚ùå Falha no upload do Cart√£o CNPJ para caso {case_id}")
                return False
                
    except httpx.HTTPStatusError as e:
        logger.error(f"‚ùå Erro HTTP na API CNPJ√°: {e.response.status_code} - {e.response.text}")
        return False
    except Exception as e:
        logger.error(f"‚ùå Erro ao gerar Cart√£o CNPJ: {e}")
        return False

async def handle_crewai_analysis_result(card_id: str, crew_response: Dict[str, Any]) -> Dict[str, Any]:
    """
    Orquestador principal que processa o resultado do an√°lise CrewAI e executa as a√ß√µes correspondentes.
    Implementa a l√≥gica de decis√£o baseada no status_geral conforme definido no PRD.
    
    Args:
        card_id: ID do card no Pipefy
        crew_response: Resposta JSON estruturada do CrewAI
    
    Returns:
        Dict com o resultado das a√ß√µes executadas
    """
    try:
        # Extrair dados da resposta CrewAI (formato real)
        status_geral = crew_response.get("status_geral")
        resumo_analise = crew_response.get("resumo_analise", "")
        pendencias = crew_response.get("pendencias", [])
        documentos_analisados = crew_response.get("documentos_analisados", [])
        proximos_passos = crew_response.get("proximos_passos", [])
        recomendacoes = crew_response.get("recomendacoes", "")
        
        # Gerar relat√≥rio detalhado formatado em Markdown baseado nos dados do CrewAI
        relatorio_detalhado = f"""# üìã Relat√≥rio de An√°lise Documental

## üìä Status Geral: {status_geral}

## üìù Resumo da An√°lise
{resumo_analise}

## üìÑ Documentos Analisados
"""
        
        for doc in documentos_analisados:
            nome = doc.get("nome", "N/A")
            status_doc = doc.get("status", "N/A")
            observacoes = doc.get("observacoes", "")
            relatorio_detalhado += f"- **{nome}**: {status_doc}\n"
            if observacoes:
                relatorio_detalhado += f"  - {observacoes}\n"
        
        if pendencias:
            relatorio_detalhado += "\n## ‚ö†Ô∏è Pend√™ncias Identificadas\n"
            for pendencia in pendencias:
                tipo = pendencia.get("tipo", "N/A")
                categoria = pendencia.get("categoria", "N/A")
                descricao = pendencia.get("descricao", "")
                acao_requerida = pendencia.get("acao_requerida", "")
                prazo_sugerido = pendencia.get("prazo_sugerido", "")
                
                relatorio_detalhado += f"### {categoria} ({tipo})\n"
                relatorio_detalhado += f"**Descri√ß√£o:** {descricao}\n\n"
                relatorio_detalhado += f"**A√ß√£o Requerida:** {acao_requerida}\n\n"
                if prazo_sugerido:
                    relatorio_detalhado += f"**Prazo Sugerido:** {prazo_sugerido}\n\n"
        
        if proximos_passos:
            relatorio_detalhado += "\n## üéØ Pr√≥ximos Passos\n"
            for i, passo in enumerate(proximos_passos, 1):
                relatorio_detalhado += f"{i}. {passo}\n"
        
        if recomendacoes:
            relatorio_detalhado += f"\n## üí° Recomenda√ß√µes\n{recomendacoes}\n"
        
        # Extrair a√ß√µes requeridas das pend√™ncias para compatibilidade
        acoes_requeridas = []
        
        # SEMPRE tentar detectar se h√° necessidade de Cart√£o CNPJ automaticamente
        import re
        # Padr√µes para detectar necessidade de Cart√£o CNPJ
        cnpj_patterns = [
            r'cart√£o\s+cnpj', r'carta\s+cnpj', r'documento\s+cnpj', 
            r'comprovante\s+cnpj', r'consulta\s+cnpj', r'certid√£o\s+cnpj',
            r'documento.*receita.*federal', r'rfb', r'cnpja'
        ]
        
        # Buscar CNPJ v√°lido no texto completo - MELHORADO
        # Padr√µes mais flex√≠veis para CNPJ: com formato (11.222.333/0001-81) ou sem formato (11222333000181)
        cnpj_patterns_flexible = [
            r'\b\d{2}[\.\s]?\d{3}[\.\s]?\d{3}[\/\s]?\d{4}[\-\s]?\d{2}\b',  # Formato tradicional
            r'\b\d{14}\b',  # Formato sem pontua√ß√£o
            r'CNPJ[:\s]*\d{2}[\.\s]?\d{3}[\.\s]?\d{3}[\/\s]?\d{4}[\-\s]?\d{2}',  # Com prefixo CNPJ
            r'CNPJ[:\s]*\d{14}',  # Com prefixo CNPJ sem pontua√ß√£o
        ]
        
        texto_completo = f"{resumo_analise} {relatorio_detalhado}"
        for pendencia in pendencias:
            texto_completo += f" {pendencia.get('descricao', '')} {pendencia.get('acao_requerida', '')}"
        
        cnpj_extraido = None
        logger.info(f"üîç Buscando CNPJ no texto: {texto_completo[:200]}...")
        
        for pattern in cnpj_patterns_flexible:
            cnpj_matches = re.findall(pattern, texto_completo, re.IGNORECASE)
            if cnpj_matches:
                # Pegar o primeiro match e limpar
                raw_cnpj = cnpj_matches[0]
                # Remover prefixo CNPJ: se existir
                if 'CNPJ' in raw_cnpj.upper():
                    raw_cnpj = re.sub(r'CNPJ[:\s]*', '', raw_cnpj, flags=re.IGNORECASE)
                
                cnpj_extraido = re.sub(r'[^\d]', '', raw_cnpj)  # Remove tudo que n√£o √© d√≠gito
                
                # Validar que tem 14 d√≠gitos
                if len(cnpj_extraido) == 14:
                    logger.info(f"üéØ CNPJ encontrado automaticamente: {cnpj_extraido} (padr√£o: {pattern})")
                    break
                else:
                    logger.warning(f"‚ö†Ô∏è CNPJ inv√°lido encontrado (tamanho {len(cnpj_extraido)}): {cnpj_extraido}")
                    cnpj_extraido = None
        
        # Verificar se h√° necessidade de Cart√£o CNPJ
        need_cnpj_card = False
        for pattern in cnpj_patterns:
            if re.search(pattern, texto_completo, re.IGNORECASE):
                need_cnpj_card = True
                logger.info(f"üîç Detectada necessidade de Cart√£o CNPJ pelo padr√£o: {pattern}")
                break
        
        # Se h√° necessidade ou se o caso √© "Pendencia_Bloqueante", tentar gerar
        if need_cnpj_card or status_geral in ["Pendencia_Bloqueante", "Pendencia_NaoBloqueante"]:
            if cnpj_extraido:
                logger.info(f"‚ûï Adicionando a√ß√£o de Cart√£o CNPJ para CNPJ: {cnpj_extraido}")
                acoes_requeridas.append({
                    "item": "Cart√£o CNPJ",
                    "acao": "GERAR_DOCUMENTO_VIA_API",
                    "parametros": {"cnpj": cnpj_extraido}
                })
            else:
                # FALLBACK: Tentar extrair CNPJ dos campos do card de Pipefy
                logger.warning(f"‚ö†Ô∏è Necessidade de Cart√£o CNPJ detectada mas nenhum CNPJ v√°lido encontrado no texto")
                logger.info(f"üîç Tentando FALLBACK: buscar CNPJ nos campos do card {card_id}")
                cnpj_from_card = await extract_cnpj_from_pipefy_card(card_id)
                if cnpj_from_card:
                    logger.info(f"‚úÖ CNPJ encontrado via FALLBACK do card: {cnpj_from_card}")
                    acoes_requeridas.append({
                        "item": "Cart√£o CNPJ",
                        "acao": "GERAR_DOCUMENTO_VIA_API",
                        "parametros": {"cnpj": cnpj_from_card}
                    })
                else:
                    logger.error(f"‚ùå CNPJ n√£o encontrado nem no texto nem nos campos do card {card_id}")
                
                # üÜï TENTAR OBTER CNPJ DO CARD DE PIPEFY COMO FALLBACK
                logger.info(f"üîç Tentando obter CNPJ dos campos do card {card_id}")
                cnpj_from_card = await extract_cnpj_from_pipefy_card(card_id)
                if cnpj_from_card:
                    logger.info(f"‚úÖ CNPJ encontrado no card: {cnpj_from_card}")
                    acoes_requeridas.append({
                        "item": "Cart√£o CNPJ",
                        "acao": "GERAR_DOCUMENTO_VIA_API",
                        "parametros": {"cnpj": cnpj_from_card}
                    })
                else:
                    logger.warning(f"‚ùå N√£o foi poss√≠vel obter CNPJ nem do texto nem do card")
        
        logger.info(f"üéØ Processando resultado CrewAI para card {card_id}")
        logger.info(f"üìä Status Geral: {status_geral}")
        logger.info(f"üìã A√ß√µes Requeridas: {len(acoes_requeridas)}")
        
        # Resultado das a√ß√µes executadas
        result = {
            "card_id": card_id,
            "status_geral": status_geral,
            "actions_executed": [],
            "success": True,
            "errors": []
        }
        
        # 1. Sempre atualizar o campo Informe CrewAI com o relat√≥rio detalhado
        logger.info(f"üìù Atualizando campo 'Informe CrewAI' no card {card_id}")
        informe_updated = await update_pipefy_informe_crewai_field(card_id, relatorio_detalhado)
        
        if informe_updated:
            result["actions_executed"].append("informe_updated")
            logger.info(f"‚úÖ Campo 'Informe CrewAI' atualizado com sucesso")
        else:
            result["errors"].append("failed_to_update_informe")
            logger.error(f"‚ùå Falha ao atualizar campo 'Informe CrewAI'")
        
        # 2. Executar a√ß√µes baseadas no status_geral
        if status_geral == "Pendencia_Bloqueante":
            logger.info(f"üö® Processando PEND√äNCIA BLOQUEANTE para card {card_id}")
            
            # Primeiro verificar se h√° a√ß√µes de CNPJ a executar ANTES de mover o card
            for acao in acoes_requeridas:
                item = acao.get("item", "")
                acao_tipo = acao.get("acao", "")
                parametros = acao.get("parametros", {})
                
                logger.info(f"üîß Executando a√ß√£o bloqueante: {acao_tipo} para item: {item}")
                
                if acao_tipo == "GERAR_DOCUMENTO_VIA_API" and "Cart√£o CNPJ" in item:
                    cnpj = parametros.get("cnpj")
                    if cnpj:
                        logger.info(f"üè¢ Gerando Cart√£o CNPJ para CNPJ: {cnpj}")
                        cartao_gerado = await gerar_e_armazenar_cartao_cnpj(card_id, cnpj)
                        if cartao_gerado:
                            result["actions_executed"].append("cartao_cnpj_generated")
                            logger.info(f"‚úÖ Cart√£o CNPJ gerado e armazenado automaticamente")
                        else:
                            result["errors"].append("failed_to_generate_cartao_cnpj")
                            logger.error(f"‚ùå Falha ao gerar Cart√£o CNPJ para CNPJ: {cnpj}")
                    else:
                        logger.warning(f"‚ö†Ô∏è CNPJ n√£o fornecido para gera√ß√£o de Cart√£o CNPJ")
                        logger.info(f"üîç Tentando extrair CNPJ do texto da pend√™ncia...")
                        import re
                        # Usar padr√µes melhorados para CNPJ - igual ao anterior
                        cnpj_patterns_improved = [
                            r'\b\d{2}[\.\s]?\d{3}[\.\s]?\d{3}[\/\s]?\d{4}[\-\s]?\d{2}\b',
                            r'\b\d{14}\b',
                            r'CNPJ[:\s]*\d{2}[\.\s]?\d{3}[\.\s]?\d{3}[\/\s]?\d{4}[\-\s]?\d{2}',
                            r'CNPJ[:\s]*\d{14}'
                        ]
                        
                        texto_completo_busca = f"{resumo_analise} {relatorio_detalhado}"
                        for pendencia in pendencias:
                            texto_completo_busca += f" {pendencia.get('descricao', '')} {pendencia.get('acao_requerida', '')}"
                        
                        cnpj_extraido_bloqueante = None
                        for pattern in cnpj_patterns_improved:
                            cnpj_matches = re.findall(pattern, texto_completo_busca, re.IGNORECASE)
                            if cnpj_matches:
                                raw_cnpj = cnpj_matches[0]
                                if 'CNPJ' in raw_cnpj.upper():
                                    raw_cnpj = re.sub(r'CNPJ[:\s]*', '', raw_cnpj, flags=re.IGNORECASE)
                                cnpj_extraido_bloqueante = re.sub(r'[^\d]', '', raw_cnpj)
                                if len(cnpj_extraido_bloqueante) == 14:
                                    break
                                else:
                                    cnpj_extraido_bloqueante = None
                        
                        if cnpj_extraido_bloqueante:
                            logger.info(f"üéØ CNPJ extra√≠do da an√°lise: {cnpj_extraido_bloqueante}")
                            cartao_gerado = await gerar_e_armazenar_cartao_cnpj(card_id, cnpj_extraido_bloqueante)
                            if cartao_gerado:
                                result["actions_executed"].append("cartao_cnpj_generated")
                                logger.info(f"‚úÖ Cart√£o CNPJ gerado com CNPJ extra√≠do")
                            else:
                                result["errors"].append("failed_to_generate_cartao_cnpj")
                                logger.error(f"‚ùå Falha ao gerar Cart√£o CNPJ com CNPJ extra√≠do")
                        else:
                            logger.warning(f"‚ùå N√£o foi poss√≠vel extrair CNPJ para gera√ß√£o do cart√£o")
            
            # Mover card para fase "Pend√™ncias Documentais"
            moved = await move_pipefy_card_to_phase(card_id, PHASE_ID_PENDENCIAS)
            if moved:
                result["actions_executed"].append("moved_to_pendencias")
                logger.info(f"‚úÖ Card movido para fase 'Pend√™ncias Documentais' (ID: {PHASE_ID_PENDENCIAS})")
            else:
                result["errors"].append("failed_to_move_to_pendencias")
                logger.error(f"‚ùå Falha ao mover card para 'Pend√™ncias Documentais' (ID: {PHASE_ID_PENDENCIAS})")
            
            # Enviar notifica√ß√£o WhatsApp para gestor
            whatsapp_sent = await send_whatsapp_notification(card_id, relatorio_detalhado)
            if whatsapp_sent:
                result["actions_executed"].append("whatsapp_notification_sent")
                logger.info(f"‚úÖ Notifica√ß√£o WhatsApp enviada ao gestor")
            else:
                result["errors"].append("failed_to_send_whatsapp")
                logger.error(f"‚ùå Falha ao enviar notifica√ß√£o WhatsApp")
        
        elif status_geral == "Pendencia_NaoBloqueante":
            logger.info(f"‚ö†Ô∏è Processando PEND√äNCIA N√ÉO BLOQUEANTE para card {card_id}")
            
            # Executar a√ß√µes autom√°ticas para pend√™ncias n√£o bloqueantes
            for acao in acoes_requeridas:
                item = acao.get("item", "")
                acao_tipo = acao.get("acao", "")
                parametros = acao.get("parametros", {})
                
                logger.info(f"üîß Executando a√ß√£o: {acao_tipo} para item: {item}")
                
                if acao_tipo == "GERAR_DOCUMENTO_VIA_API" and "Cart√£o CNPJ" in item:
                    cnpj = parametros.get("cnpj")
                    if cnpj:
                        logger.info(f"üè¢ Gerando Cart√£o CNPJ para CNPJ: {cnpj}")
                        cartao_gerado = await gerar_e_armazenar_cartao_cnpj(card_id, cnpj)
                        if cartao_gerado:
                            result["actions_executed"].append("cartao_cnpj_generated")
                            logger.info(f"‚úÖ Cart√£o CNPJ gerado e armazenado automaticamente")
                        else:
                            result["errors"].append("failed_to_generate_cartao_cnpj")
                            logger.error(f"‚ùå Falha ao gerar Cart√£o CNPJ para CNPJ: {cnpj}")
                    else:
                        logger.warning(f"‚ö†Ô∏è CNPJ n√£o fornecido para gera√ß√£o de Cart√£o CNPJ")
                        logger.info(f"üîç Tentando extrair CNPJ do texto da pend√™ncia...")
                        import re
                        # Usar padr√µes melhorados para CNPJ  
                        cnpj_patterns_improved = [
                            r'\b\d{2}[\.\s]?\d{3}[\.\s]?\d{3}[\/\s]?\d{4}[\-\s]?\d{2}\b',
                            r'\b\d{14}\b',
                            r'CNPJ[:\s]*\d{2}[\.\s]?\d{3}[\.\s]?\d{3}[\/\s]?\d{4}[\-\s]?\d{2}',
                            r'CNPJ[:\s]*\d{14}'
                        ]
                        
                        cnpj_extraido_local = None
                        busca_texto = f"{acao.get('descricao', '')} {texto_completo}"
                        
                        for pattern in cnpj_patterns_improved:
                            cnpj_matches = re.findall(pattern, busca_texto, re.IGNORECASE)
                            if cnpj_matches:
                                raw_cnpj = cnpj_matches[0]
                                if 'CNPJ' in raw_cnpj.upper():
                                    raw_cnpj = re.sub(r'CNPJ[:\s]*', '', raw_cnpj, flags=re.IGNORECASE)
                                cnpj_extraido_local = re.sub(r'[^\d]', '', raw_cnpj)
                                if len(cnpj_extraido_local) == 14:
                                    break
                                else:
                                    cnpj_extraido_local = None
                        
                        if cnpj_extraido_local:
                            logger.info(f"üéØ CNPJ extra√≠do melhorado: {cnpj_extraido_local}")
                            cartao_gerado = await gerar_e_armazenar_cartao_cnpj(card_id, cnpj_extraido_local)
                            if cartao_gerado:
                                result["actions_executed"].append("cartao_cnpj_generated")
                                logger.info(f"‚úÖ Cart√£o CNPJ gerado com CNPJ extra√≠do")
                            else:
                                result["errors"].append("failed_to_generate_cartao_cnpj")
                                logger.error(f"‚ùå Falha ao gerar Cart√£o CNPJ com CNPJ extra√≠do")
                        else:
                            logger.warning(f"‚ùå N√£o foi poss√≠vel extrair CNPJ para gera√ß√£o do cart√£o")
                
                elif acao_tipo == "NOTIFICAR_EQUIPE_CADASTRO":
                    # Por enquanto, o movimento do card serve como notifica√ß√£o
                    logger.info(f"üì¢ Notifica√ß√£o para equipe de cadastro: {item}")
                    result["actions_executed"].append("team_notification_logged")
                
                elif acao_tipo == "SOLICITAR_AO_GESTOR":
                    # A√ß√£o que ser√° tratada pelo movimento para fase de pend√™ncias
                    logger.info(f"üë§ Solicita√ß√£o ao gestor: {item}")
                    result["actions_executed"].append("manager_request_logged")
            
            # Mover card para fase "Emitir documentos"
            moved = await move_pipefy_card_to_phase(card_id, PHASE_ID_EMITIR_DOCS)
            if moved:
                result["actions_executed"].append("moved_to_emitir_docs")
                logger.info(f"‚úÖ Card movido para fase 'Emitir documentos' (ID: {PHASE_ID_EMITIR_DOCS})")
            else:
                result["errors"].append("failed_to_move_to_emitir_docs")
                logger.error(f"‚ùå Falha ao mover card para 'Emitir documentos' (ID: {PHASE_ID_EMITIR_DOCS})")
        
        elif status_geral == "Aprovado":
            logger.info(f"‚úÖ Processando APROVA√á√ÉO para card {card_id}")
            
            # Atualizar campo com mensagem de aprova√ß√£o
            aprovacao_message = "‚úÖ **DOCUMENTA√á√ÉO APROVADA**\n\nTodos os documentos est√£o em conformidade com o checklist. O caso seguir√° para a pr√≥xima etapa de an√°lise de risco."
            informe_aprovacao = await update_pipefy_informe_crewai_field(card_id, aprovacao_message)
            
            if informe_aprovacao:
                result["actions_executed"].append("approval_message_updated")
                logger.info(f"‚úÖ Mensagem de aprova√ß√£o atualizada")
            
            # Mover card para fase "Aprovado"
            moved = await move_pipefy_card_to_phase(card_id, PHASE_ID_APROVADO)
            if moved:
                result["actions_executed"].append("moved_to_aprovado")
                logger.info(f"‚úÖ Card movido para fase 'Aprovado' (ID: {PHASE_ID_APROVADO})")
            else:
                result["errors"].append("failed_to_move_to_aprovado")
                logger.error(f"‚ùå Falha ao mover card para 'Aprovado' (ID: {PHASE_ID_APROVADO})")
        
        else:
            logger.error(f"‚ùå Status geral desconhecido: '{status_geral}' para card {card_id}")
            result["success"] = False
            result["errors"].append(f"unknown_status: {status_geral}")
        
        # Determinar sucesso geral
        if result["errors"]:
            result["success"] = False
            logger.warning(f"‚ö†Ô∏è Processamento conclu√≠do com erros para card {card_id}: {result['errors']}")
        else:
            logger.info(f"‚úÖ Processamento conclu√≠do com sucesso para card {card_id}")
        
        return result
        
    except Exception as e:
        logger.error(f"‚ùå Erro cr√≠tico no orquestrador para card {card_id}: {e}")
        return {
            "card_id": card_id,
            "success": False,
            "error": str(e),
            "actions_executed": [],
            "errors": ["critical_orchestrator_error"]
        }

# --- Endpoint Principal ---
@app.post("/webhook/pipefy")
async def handle_pipefy_webhook(request: Request, background_tasks: BackgroundTasks, x_pipefy_signature: Optional[str] = Header(None)):
    """
    Recebe webhooks do Pipefy, processa anexos, armazena no Supabase e chama CrewAI diretamente.
    VERSI√ìN HTTP DIRECTA: Mantiene modularidad pero usa comunicaci√≥n HTTP directa.
    """
    try:
        # Capturar el cuerpo raw sin Pydantic
        raw_body = await request.body()
        raw_body_str = raw_body.decode('utf-8', errors='ignore')
        
        logger.info(f"üì• Webhook Pipefy recebido. Payload length: {len(raw_body_str)}")
        
        # üîê VALIDAR WEBHOOK SECRET
        if not validate_pipefy_webhook_signature(raw_body, x_pipefy_signature, PIPEFY_WEBHOOK_SECRET):
            logger.error("‚ùå Assinatura do webhook Pipefy inv√°lida")
            raise HTTPException(status_code=401, detail="Assinatura do webhook inv√°lida")
        
        # Parsear JSON manualmente
        try:
            payload_data = json.loads(raw_body_str)
        except json.JSONDecodeError as e:
            logger.error(f"ERRO: JSON inv√°lido recebido: {e}")
            raise HTTPException(status_code=400, detail="JSON inv√°lido")
        
        # Validar estructura b√°sica manualmente
        if not isinstance(payload_data, dict):
            logger.error("ERRO: Payload n√£o √© um objeto JSON v√°lido")
            raise HTTPException(status_code=400, detail="Payload deve ser um objeto JSON")
        
        data = payload_data.get('data')
        if not data or not isinstance(data, dict):
            logger.error("ERRO: Campo 'data' ausente ou inv√°lido")
            raise HTTPException(status_code=400, detail="Campo 'data' obrigat√≥rio")
        
        card = data.get('card')
        if not card or not isinstance(card, dict):
            logger.error("ERRO: Campo 'card' ausente ou inv√°lido")
            raise HTTPException(status_code=400, detail="Campo 'card' obrigat√≥rio")
        
        # Extrair e convertir card_id
        card_id_raw = card.get('id')
        if card_id_raw is None:
            logger.error("ERRO: Campo 'card.id' ausente")
            raise HTTPException(status_code=400, detail="Campo 'card.id' obrigat√≥rio")
        
        card_id_str = str(card_id_raw)
        logger.info(f"üìã Processando card_id: {card_id_str}")
        
        # Extraer pipe_id si est√° disponible
        pipe_id = None
        if 'pipe' in card and isinstance(card['pipe'], dict):
            pipe_id = card['pipe'].get('id')
            if pipe_id:
                pipe_id = str(pipe_id)
                logger.info(f"üîó Pipe ID encontrado: {pipe_id}")
        
        # Extraer action si existe
        action = data.get('action', 'unknown')
        logger.info(f"‚ö° A√ß√£o: {action}")

        # üéØ FILTRAR POR FASE 338000020 (Triagem Documentos AI)
        current_phase = card.get('current_phase')
        if not current_phase or not isinstance(current_phase, dict):
            # Intentar enriquecer el payload consultando la API de Pipefy
            logger.warning(f"‚ö†Ô∏è Card {card_id_str} sem informa√ß√£o de fase atual. Tentando enriquecer via API Pipefy...")
            try:
                from src.integrations.pipefy_client import pipefy_client
                card_info = await pipefy_client.get_card_info(card_id_str)
                if card_info and isinstance(card_info, dict) and card_info.get('current_phase'):
                    card['current_phase'] = card_info['current_phase']
                    current_phase = card['current_phase']
                    logger.info(f"‚úÖ Fase atual obtida via API: {current_phase}")
                else:
                    logger.warning(f"‚ö†Ô∏è Card {card_id_str} ainda sem informa√ß√£o de fase ap√≥s consulta √† API. Ignorando webhook.")
                    return {
                        "status": "ignored",
                        "reason": "no_current_phase_info",
                        "card_id": card_id_str,
                        "message": "Webhook ignorado - sem informa√ß√£o de fase atual (mesmo ap√≥s consulta √† API)"
                    }
            except Exception as e:
                logger.error(f"‚ùå Erro ao consultar API Pipefy para card {card_id_str}: {e}")
                return {
                    "status": "ignored",
                    "reason": "no_current_phase_info_api_error",
                    "card_id": card_id_str,
                    "message": f"Webhook ignorado - erro ao consultar API Pipefy: {e}"
                }
        
        current_phase_id = str(current_phase.get('id', ''))
        current_phase_name = current_phase.get('name', 'Unknown')
        
        logger.info(f"üìç Fase atual do card: {current_phase_name} (ID: {current_phase_id})")
        
        # Verificar se est√° na fase de triagem (338000020)
        if current_phase_id != PHASE_ID_TRIAGEM:
            logger.info(f"‚è≠Ô∏è Card {card_id_str} n√£o est√° na fase de triagem (ID: {current_phase_id}). Webhook ignorado.")
            return {
                "status": "ignored",
                "reason": "not_triagem_phase",
                "card_id": card_id_str,
                "current_phase_id": current_phase_id,
                "current_phase_name": current_phase_name,
                "expected_phase_id": PHASE_ID_TRIAGEM,
                "message": f"Webhook ignorado - card n√£o est√° na fase de triagem. Fase atual: {current_phase_name}"
            }
        
        logger.info(f"‚úÖ Card {card_id_str} est√° na fase de triagem. Iniciando processamento...")

        # Procesar documentos anexos del card
        attachments_from_pipefy = await get_pipefy_card_attachments(card_id_str)
        processed_documents: List[Dict[str, Any]] = []

        if not attachments_from_pipefy:
            logger.info(f"üìÑ Nenhum anexo encontrado para o card {card_id_str}.")
        else:
            logger.info(f"üìÑ {len(attachments_from_pipefy)} anexos encontrados para o card {card_id_str}.")
            for att in attachments_from_pipefy:
                logger.info(f"‚¨áÔ∏è Processando anexo: {att.name}...")
                
                temp_file = await download_file_to_temp(att.path, att.name)
                if temp_file:
                    storage_url = await upload_to_supabase_storage_async(temp_file, card_id_str, att.name)
                    if storage_url:
                        document_tag = await determine_document_tag(att.name)
                        success_db = await register_document_in_db(card_id_str, att.name, document_tag, storage_url, pipe_id)
                        if success_db:
                            processed_documents.append({
                                "name": att.name,
                                "file_url": storage_url,
                                "document_tag": document_tag
                            })
                        else:
                            logger.warning(f"‚ö†Ô∏è Falha ao fazer upload do anexo '{att.name}' para Supabase Storage.")
                else:
                    logger.warning(f"‚ö†Ô∏è Falha ao baixar o anexo '{att.name}' do Pipefy.")
        
        logger.info(f"‚úÖ {len(processed_documents)} documentos processados com sucesso.")

        # Obtener URL del checklist
        logger.info("üîç Buscando URL do checklist...")
        checklist_url = await get_checklist_url_from_supabase()
        logger.info(f"üìã URL do checklist: {checklist_url}")
        
        # üîó LLAMADA HTTP DIRECTA A CREWAI (en background para no bloquear respuesta)
        background_tasks.add_task(
            call_crewai_analysis_service,
            card_id_str,
            processed_documents,
            checklist_url,
            pipe_id
        )

        logger.info(f"üöÄ Tarea CrewAI programada en background para case_id: {card_id_str}")
        logger.info(f"üìä Resumen del procesamiento:")
        logger.info(f"   - Card ID: {card_id_str}")
        logger.info(f"   - Pipe ID: {pipe_id}")
        logger.info(f"   - Documentos procesados: {len(processed_documents)}")
        logger.info(f"   - Checklist URL: {checklist_url}")
        logger.info(f"   - Servicio CrewAI: {CREWAI_SERVICE_URL}")

        return {
            "status": "success",
            "message": f"Webhook para card {card_id_str} processado. {len(processed_documents)} documentos processados.",
            "service": "document_ingestion_service",
            "card_id": card_id_str,
            "pipe_id": pipe_id,
            "documents_processed": len(processed_documents),
            "crewai_analysis": "initiated_in_background",
            "architecture": "modular_http_direct",
            "communication": "http_direct",
            "cold_start_handling": "enabled"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå ERRO inesperado no webhook: {e}")
        import traceback
        logger.error(f"TRACEBACK: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"Erro interno: {str(e)}")

# üîî WEBHOOK SUPABASE - Endpoint para recibir notificaciones de nuevos informes
@app.post('/webhook/supabase')
async def supabase_webhook(request: Request):
    """
    Webhook que recibe notificaciones de Supabase cuando se inserta un nuevo informe.
    VERSI√ìN COMPLETA: Ejecuta toda la l√≥gica de negocio incluyendo movimiento de cards y generaci√≥n de cart√£o CNPJ.
    """
    try:
        data = await request.json()
        logger.info(f"üì® Webhook Supabase recebido: {json.dumps(data, indent=2)}")
        
        # Verificar que es un INSERT en la tabla informe_cadastro
        if data.get('type') != 'INSERT' or data.get('table') != 'informe_cadastro':
            logger.info(f"‚è≠Ô∏è Webhook ignorado - Tipo: {data.get('type')}, Tabla: {data.get('table')}")
            return {"status": "ignored", "reason": "not_informe_insert"}
        
        record = data.get('record', {})
        case_id = record.get('case_id')
        informe_json_str = record.get('informe')
        status = record.get('status')
        
        if not case_id or not informe_json_str:
            logger.warning(f"‚ö†Ô∏è Webhook com dados incompletos - case_id: {case_id}, informe presente: {bool(informe_json_str)}")
            raise HTTPException(status_code=400, detail="case_id ou informe ausente")
        
        logger.info(f"üéØ Processando informe completo para case_id: {case_id}")
        logger.info(f"   - Status: {status}")
        logger.info(f"   - Tamanho do informe: {len(informe_json_str)} caracteres")
        
        # Parsear el JSON del informe para obtener la estructura completa
        try:
            informe_data = json.loads(informe_json_str)
            logger.info(f"üìä Informe parseado - Status geral: {informe_data.get('status_geral')}")
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Erro ao parsear JSON do informe: {e}")
            raise HTTPException(status_code=400, detail="JSON do informe inv√°lido")
        
        # Ejecutar el orquestrador principal de forma as√≠ncrona
        async def process_complete_workflow():
            try:
                logger.info(f"üöÄ Iniciando fluxo completo para case_id: {case_id}")
                
                # 1. Executar orquestrador principal com todos os dados do CrewAI
                orchestrator_result = await handle_crewai_analysis_result(case_id, informe_data)
                
                if orchestrator_result.get("success"):
                    logger.info(f"‚úÖ Fluxo completo executado com sucesso para case_id: {case_id}")
                    logger.info(f"üéØ A√ß√µes executadas: {orchestrator_result.get('actions_executed', [])}")
                else:
                    logger.error(f"‚ùå Fluxo completo falhou para case_id: {case_id}")
                    logger.error(f"‚ùå Erros: {orchestrator_result.get('errors', [])}")
                    
            except Exception as e:
                logger.error(f"‚ùå Erro no fluxo completo para case_id {case_id}: {e}")
        
        # Executar em background
        asyncio.create_task(process_complete_workflow())
        
        return {
            "status": "success", 
            "message": "Webhook processado - fluxo completo iniciado",
            "case_id": case_id,
            "strategy": "complete_workflow_orchestrator",
            "informe_status": informe_data.get('status_geral', 'unknown')
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erro no webhook Supabase: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Agregar endpoint alternativo para el webhook
@app.post('/webhook/supabase/informe-created')
async def supabase_informe_created_webhook(request: Request):
    """
    Endpoint alternativo para el webhook de Supabase - redirige al principal.
    """
    logger.info("üîÑ Webhook alternativo recebido - redirecionando para principal")
    return await supabase_webhook(request)

@app.post("/test/check-and-move-card")
async def test_check_and_move_card(card_id: str):
    """
    Endpoint de prueba para verificar la fase actual del card y moverlo si es necesario.
    √ötil para testing del nuevo sistema de manejo de fases.
    """
    try:
        logger.info(f"üß™ Test: Verificando fase y movimiento para card {card_id}")
        
        # Verificar fase actual y mover si es necesario
        phase_info = await get_card_current_phase_and_move_if_needed(card_id)
        
        if "error" in phase_info:
            raise HTTPException(
                status_code=500, 
                detail=f"Error al verificar fase del card: {phase_info}"
            )
        
        return {
            "status": "success",
            "message": f"Verificaci√≥n de fase completada para card {card_id}",
            "phase_info": phase_info
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå ERRO en test endpoint: {e}")
        raise HTTPException(status_code=500, detail=f"Erro interno: {str(e)}")

@app.post("/test/update-pipefy-with-phase-handling")
async def test_update_pipefy_with_phase_handling(
    case_id: str,
    informe_content: str
):
    """
    Endpoint de prueba para actualizar el campo Informe CrewAI con manejo autom√°tico de fases.
    Incluye verificaci√≥n de fase, movimiento si es necesario, y actualizaci√≥n del campo.
    """
    try:
        logger.info(f"üß™ Test: Actualizaci√≥n completa con manejo de fases para case_id {case_id}")
        
        success = await update_pipefy_informe_crewai_field(case_id, informe_content)
        
        if success:
            return {
                "status": "success",
                "message": f"Campo actualizado exitosamente con manejo de fases para case_id {case_id}",
                "case_id": case_id,
                "feature": "automatic_phase_handling"
            }
        else:
            raise HTTPException(
                status_code=500, 
                detail=f"Error al actualizar campo con manejo de fases para case_id {case_id}"
            )
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå ERRO en test endpoint: {e}")
        raise HTTPException(status_code=500, detail=f"Erro interno: {str(e)}")

@app.post("/test/update-form-field")
async def test_update_form_field(request: Request):
    """
    Endpoint de prueba para verificar la actualizaci√≥n de campos en formulario.
    CORREGIDO: Usa la sintaxis correcta de updateCardField de Pipefy.
    """
    try:
        data = await request.json()
        card_id = data.get('card_id')
        test_content = data.get('test_content', f'üß™ Prueba de campo en formulario - {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
        
        if not card_id:
            raise HTTPException(status_code=400, detail="card_id es requerido")
        
        logger.info(f"üß™ Prueba de actualizaci√≥n de campo en formulario para card: {card_id}")
        
        # Ejecutar actualizaci√≥n usando la funci√≥n corregida
        success = await update_pipefy_informe_crewai_field(card_id, test_content)
        
        if success:
            return {
                "success": True,
                "card_id": card_id,
                "test_content": test_content,
                "strategy": "form_field_direct_corrected",
                "message": "Campo actualizado exitosamente con sintaxis corregida"
            }
        else:
            raise HTTPException(
                status_code=500, 
                detail="Error al actualizar campo con sintaxis corregida"
            )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error en prueba de campo en formulario: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error interno: {str(e)}")

@app.post("/test/robust-field-handling")
async def test_robust_field_handling(request: Request):
    """
    Endpoint de prueba para la funcionalidad robusta de manejo de campos Pipefy.
    
    FUNCIONALIDAD:
    - Detecta si el campo 'Informe CrewAI' existe (tiene valor)
    - Si no existe, lo crea autom√°ticamente en la fase actual
    - Inicializa con placeholder para que aparezca en la API
    - Actualiza con el contenido real del informe
    
    SOLUCIONA: El comportamiento espec√≠fico de Pipefy donde los campos
    solo aparecen en la API cuando tienen alg√∫n valor asignado.
    """
    try:
        data = await request.json()
        card_id = data.get('card_id')
        test_content = data.get('test_content', f'üß™ Prueba robusta de campo Pipefy - {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
        
        if not card_id:
            raise HTTPException(status_code=400, detail="card_id es requerido")
        
        logger.info(f"üß™ PRUEBA ROBUSTA: Manejo de campos Pipefy para card: {card_id}")
        logger.info(f"üéØ OBJETIVO: Solucionar comportamiento donde campos sin valor no aparecen en API")
        
        # Ejecutar actualizaci√≥n robusta
        success = await update_pipefy_informe_crewai_field(card_id, test_content)
        
        if success:
            return {
                "success": True,
                "card_id": card_id,
                "test_content": test_content,
                "strategy": "robust_field_handling",
                "features": [
                    "Detecci√≥n autom√°tica de campos existentes",
                    "Creaci√≥n autom√°tica si no existe",
                    "Inicializaci√≥n con placeholder",
                    "Actualizaci√≥n con contenido real",
                    "Manejo del comportamiento espec√≠fico de Pipefy"
                ],
                "message": "Campo manejado exitosamente con estrategia robusta"
            }
        else:
            raise HTTPException(
                status_code=500, 
                detail="Error en manejo robusto de campo"
            )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error en prueba robusta: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error interno: {str(e)}")

@app.get("/test/field-detection/{card_id}")
async def test_field_detection(card_id: str):
    """
    Endpoint para probar solo la detecci√≥n de campos sin actualizar nada.
    √ötil para debugging y entender el comportamiento de Pipefy.
    """
    try:
        logger.info(f"üîç PRUEBA DE DETECCI√ìN: Analizando campos del card {card_id}")
        
        # Solo detectar, no actualizar
        field_result = await get_pipefy_field_id_for_informe_crewai(card_id)
        
        if isinstance(field_result, str):
            return {
                "field_found": True,
                "field_id": field_result,
                "card_id": card_id,
                "message": "Campo 'Informe CrewAI' encontrado exitosamente",
                "behavior": "Campo tiene valor y aparece en la API"
            }
        elif isinstance(field_result, dict) and field_result.get("field_not_found"):
            return {
                "field_found": False,
                "phase_id": field_result.get("phase_id"),
                "phase_name": field_result.get("phase_name"),
                "card_id": card_id,
                "message": "Campo 'Informe CrewAI' no encontrado",
                "behavior": "Campo no tiene valor y no aparece en la API",
                "solution": "Necesita creaci√≥n autom√°tica o asignaci√≥n de valor inicial"
            }
        else:
            return {
                "field_found": False,
                "error": "Error inesperado en detecci√≥n",
                "card_id": card_id,
                "result": field_result
            }
        
    except Exception as e:
        logger.error(f"‚ùå Error en detecci√≥n de campo: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error interno: {str(e)}")

@app.get("/")
async def root():
    return {
        "service": "Document Ingestion Service - HTTP Direct",
        "description": "Servicio modular para ingesti√≥n de documentos con comunicaci√≥n HTTP directa",
        "architecture": "modular",
        "communication": "http_direct",
        "crewai_service": CREWAI_SERVICE_URL
    }

@app.get("/api/v1/documentos/{case_id}")
async def get_documents_for_case(case_id: str):
    """
    Endpoint para obtener documentos de un caso espec√≠fico.
    Usado por el servicio CrewAI para acceder a los documentos procesados.
    """
    try:
        logger.info(f"üìÑ Solicitando documentos para case_id: {case_id}")
        
        # Obtener documentos desde Supabase
        def sync_get_documents():
            response = supabase.table('documents').select('*').eq('case_id', case_id).execute()
            return response.data
        
        documents = await asyncio.to_thread(sync_get_documents)
        
        if not documents:
            logger.warning(f"‚ö†Ô∏è No se encontraron documentos para case_id: {case_id}")
            return {
                "case_id": case_id,
                "documents": [],
                "count": 0,
                "message": "No se encontraron documentos para este caso"
            }
        
        # Formatear documentos para CrewAI
        formatted_documents = []
        for doc in documents:
            formatted_doc = {
                "name": doc.get('name'),
                "file_url": doc.get('file_url'),
                "document_tag": doc.get('document_tag'),
                "uploaded_at": doc.get('uploaded_at'),
                "type": "application/pdf"  # Asumimos PDF por defecto
            }
            formatted_documents.append(formatted_doc)
        
        logger.info(f"‚úÖ Encontrados {len(formatted_documents)} documentos para case_id: {case_id}")
        
        return {
            "case_id": case_id,
            "documents": formatted_documents,
            "count": len(formatted_documents),
            "message": "Documentos obtenidos exitosamente"
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error al obtener documentos para {case_id}: {str(e)}")
        raise HTTPException(
            status_code=500, 
            detail=f"Error interno al obtener documentos: {str(e)}"
        )

@app.post("/api/v1/cliente/enriquecer")
async def enriquecer_cliente(request: Request):
    """
    Endpoint para enriquecer datos de cliente con CNPJ.
    Usado por herramientas CrewAI.
    """
    try:
        body = await request.json()
        cnpj = body.get("cnpj")
        case_id = body.get("case_id")
        
        if not cnpj:
            return {"success": False, "message": "CNPJ es requerido"}
        
        logger.info(f"üîç Enriqueciendo cliente CNPJ: {cnpj} para case_id: {case_id}")
        
        # Generar cart√£o CNPJ (esto ya existe)
        result = await gerar_e_armazenar_cartao_cnpj(case_id, cnpj)
        
        if result:
            return {
                "success": True,
                "message": f"Cliente CNPJ {cnpj} enriquecido exitosamente",
                "data": {"cnpj": cnpj, "case_id": case_id}
            }
        else:
            return {
                "success": False,
                "message": f"Error al enriquecer cliente CNPJ {cnpj}"
            }
            
    except Exception as e:
        logger.error(f"‚ùå Error en enriquecer_cliente: {e}")
        return {"success": False, "message": f"Error interno: {str(e)}"}

@app.post("/api/v1/whatsapp/enviar")
async def enviar_whatsapp(request: Request):
    """
    Endpoint para enviar notificaciones WhatsApp.
    Usado por herramientas CrewAI.
    """
    try:
        body = await request.json()
        card_id = body.get("card_id")
        mensaje = body.get("mensaje")
        
        if not card_id or not mensaje:
            return {"success": False, "message": "card_id y mensaje son requeridos"}
        
        logger.info(f"üì± Enviando WhatsApp para card_id: {card_id}")
        
        # Usar funci√≥n existente
        result = await send_whatsapp_notification(card_id, mensaje)
        
        if result:
            return {
                "success": True,
                "message": f"WhatsApp enviado exitosamente para card {card_id}"
            }
        else:
            return {
                "success": False,
                "message": f"Error al enviar WhatsApp para card {card_id}"
            }
            
    except Exception as e:
        logger.error(f"‚ùå Error en enviar_whatsapp: {e}")
        return {"success": False, "message": f"Error interno: {str(e)}"}

@app.post("/api/v1/pipefy/actualizar")
async def actualizar_pipefy(request: Request):
    """
    Endpoint para actualizar campos en Pipefy.
    Usado por herramientas CrewAI.
    """
    try:
        body = await request.json()
        card_id = body.get("card_id")
        campo = body.get("campo")
        valor = body.get("valor")
        
        if not card_id or not campo or not valor:
            return {"success": False, "message": "card_id, campo y valor son requeridos"}
        
        logger.info(f"üìù Actualizando campo '{campo}' en card: {card_id}")
        
        # Para campo "informe_crewai", usar funci√≥n espec√≠fica
        if campo.lower() in ["informe_crewai", "informe_crewai_2"]:
            result = await update_pipefy_informe_crewai_field(card_id, valor)
        else:
            # Para otros campos, se podr√≠a implementar una funci√≥n gen√©rica
            result = False
            logger.warning(f"‚ö†Ô∏è Campo '{campo}' no soportado actualmente")
        
        if result:
            return {
                "success": True,
                "message": f"Campo '{campo}' actualizado exitosamente en card {card_id}"
            }
        else:
            return {
                "success": False,
                "message": f"Error al actualizar campo '{campo}' en card {card_id}"
            }
            
    except Exception as e:
        logger.error(f"‚ùå Error en actualizar_pipefy: {e}")
        return {"success": False, "message": f"Error interno: {str(e)}"}

@app.get("/health")
async def health_check():
    """Endpoint de verifica√ß√£o de sa√∫de con estado del servicio CrewAI."""
    
    # Verificar estado del servicio CrewAI
    crewai_status = "unknown"
    crewai_response_time = None
    
    try:
        start_time = datetime.now()
        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.get(f"{CREWAI_SERVICE_URL}/health")
            end_time = datetime.now()
            crewai_response_time = (end_time - start_time).total_seconds()
            
            if response.status_code == 200:
                crewai_status = "healthy"
            else:
                crewai_status = f"unhealthy_status_{response.status_code}"
    except httpx.TimeoutException:
        crewai_status = "timeout"
    except Exception as e:
        crewai_status = f"error_{str(e)[:50]}"
    
    return {
        "status": "healthy",
        "service": "document_ingestion_service",
        "supabase_configured": bool(SUPABASE_URL and SUPABASE_SERVICE_KEY),
        "pipefy_configured": bool(PIPEFY_TOKEN),
        "storage_bucket": SUPABASE_STORAGE_BUCKET_NAME,
        "crewai_service": CREWAI_SERVICE_URL,
        "crewai_status": crewai_status,
        "crewai_response_time_seconds": crewai_response_time,
        "architecture": "modular_http_direct",
        "communication": "http_direct",
        "cold_start_handling": "enabled"
    }

# üß™ Funci√≥n para detectar la fase actual del card y moverlo si es necesario
# NOTA: Mantenida para compatibilidad, pero no necesaria con la nueva estrategia
async def get_card_current_phase_and_move_if_needed(card_id: str) -> Dict[str, Any]:
    """
    Detecta la fase actual del card y lo mueve a la fase de destino si es necesario.
    OBSOLETA: No necesaria con campos en formulario, pero mantenida para compatibilidad.
    """
    # Funci√≥n mantenida para compatibilidad pero no usada en la nueva estrategia
    return {"status": "not_needed", "message": "Campo en formulario - no requiere movimiento de fase"}

# üß™ ENDPOINT DE PRUEBA - Para probar el orquestador directamente
@app.post("/test/orchestrator")
async def test_orchestrator(request: Request):
    """
    Endpoint de prueba para probar el orquestador handle_crewai_analysis_result directamente.
    Permite simular diferentes respuestas JSON del CrewAI para validar el flujo completo.
    """
    try:
        data = await request.json()
        card_id = data.get('card_id')
        
        if not card_id:
            raise HTTPException(status_code=400, detail="card_id es requerido")
        
        # Respuesta de prueba por defecto o personalizada
        test_crew_response = data.get('crew_response', {
            "status_geral": "Pendencia_NaoBloqueante",
            "relatorio_detalhado": "## Relat√≥rio de An√°lise Documental\n\n**Status:** Pend√™ncia N√£o Bloqueante\n\n### Documentos Analisados:\n- ‚úÖ Contrato Social: Presente e v√°lido\n- ‚ö†Ô∏è Cart√£o CNPJ: Ausente ou desatualizado\n\n### A√ß√µes Requeridas:\n- Gerar novo Cart√£o CNPJ via API\n\n### Observa√ß√µes:\n- Documenta√ß√£o principal est√° em conformidade\n- Pend√™ncia pode ser resolvida automaticamente",
            "acoes_requeridas": [
                {
                    "item": "Cart√£o CNPJ",
                    "acao": "GERAR_DOCUMENTO_VIA_API",
                    "parametros": {
                        "cnpj": "12345678000195",
                        "detalhes": "Cart√£o CNPJ ausente ou com mais de 90 dias"
                    }
                }
            ]
        })
        
        logger.info(f"üß™ TESTE ORQUESTRADOR: Executando para card {card_id}")
        logger.info(f"üìã Resposta simulada: {test_crew_response.get('status_geral')}")
        
        # Executar orquestrador
        orchestration_result = await handle_crewai_analysis_result(card_id, test_crew_response)
        
        return {
            "success": True,
            "card_id": card_id,
            "test_crew_response": test_crew_response,
            "orchestration_result": orchestration_result,
            "message": "Teste do orquestrador executado com sucesso",
            "endpoint": "test_orchestrator"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erro no teste do orquestrador: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erro interno: {str(e)}")

@app.post("/test/robust-field-handling")
async def test_robust_field_handling(request: Request):
    """
    Endpoint de prueba para la funcionalidad robusta de manejo de campos Pipefy.
    
    FUNCIONALIDAD:
    - Detecta si el campo 'Informe CrewAI' existe (tiene valor)
    - Si no existe, lo crea autom√°ticamente en la fase actual
    - Inicializa con placeholder para que aparezca en la API
    - Actualiza con el contenido real del informe
    
    SOLUCIONA: El comportamiento espec√≠fico de Pipefy donde los campos
    solo aparecen en la API cuando tienen alg√∫n valor asignado.
    """
    try:
        data = await request.json()
        card_id = data.get('card_id')
        test_content = data.get('test_content', f'üß™ Prueba robusta de campo Pipefy - {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
        
        if not card_id:
            raise HTTPException(status_code=400, detail="card_id es requerido")
        
        logger.info(f"üß™ PRUEBA ROBUSTA: Manejo de campos Pipefy para card: {card_id}")
        logger.info(f"üéØ OBJETIVO: Solucionar comportamiento donde campos sin valor no aparecen en API")
        
        # Ejecutar actualizaci√≥n robusta
        success = await update_pipefy_informe_crewai_field(card_id, test_content)
        
        if success:
            return {
                "success": True,
                "card_id": card_id,
                "test_content": test_content,
                "strategy": "robust_field_handling",
                "features": [
                    "Detecci√≥n autom√°tica de campos existentes",
                    "Creaci√≥n autom√°tica si no existe",
                    "Inicializaci√≥n con placeholder",
                    "Actualizaci√≥n con contenido real",
                    "Manejo del comportamiento espec√≠fico de Pipefy"
                ],
                "message": "Campo manejado exitosamente con estrategia robusta"
            }
        else:
            raise HTTPException(
                status_code=500, 
                detail="Error en manejo robusto de campo"
            )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error en prueba robusta: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error interno: {str(e)}")

# üß™ ENDPOINT DE PRUEBA - Escenarios predefinidos del orquestador
@app.post("/test/orchestrator-scenarios")
async def test_orchestrator_scenarios(request: Request):
    """
    Endpoint de prueba con escenarios predefinidos para el orquestador.
    Permite probar los 3 flujos principales: Aprovado, Pendencia_Bloqueante, Pendencia_NaoBloqueante.
    """
    try:
        data = await request.json()
        card_id = data.get('card_id')
        scenario = data.get('scenario', 'pendencia_nao_bloqueante')
        
        if not card_id:
            raise HTTPException(status_code=400, detail="card_id es requerido")
        
        # Escenarios predefinidos
        scenarios = {
            "aprovado": {
                "status_geral": "Aprovado",
                "relatorio_detalhado": "## ‚úÖ DOCUMENTA√á√ÉO APROVADA\n\n### An√°lise Completa:\n- ‚úÖ Contrato Social: V√°lido e atualizado\n- ‚úÖ Cart√£o CNPJ: Presente e dentro da validade\n- ‚úÖ Documentos dos s√≥cios: Completos e leg√≠veis\n- ‚úÖ Procura√ß√£o: Assinada e reconhecida\n\n### Conclus√£o:\nToda a documenta√ß√£o est√° em conformidade com o checklist. O caso pode prosseguir para a pr√≥xima etapa de an√°lise de risco.",
                "acoes_requeridas": []
            },
            "pendencia_bloqueante": {
                "status_geral": "Pendencia_Bloqueante",
                "relatorio_detalhado": "## üö® PEND√äNCIA CR√çTICA DETECTADA\n\n### Problemas Identificados:\n- ‚ùå Contrato Social: SEM N√öMERO DE REGISTRO na Junta Comercial\n- ‚ùå RG do s√≥cio: Documento ileg√≠vel\n- ‚ö†Ô∏è Procura√ß√£o: Falta reconhecimento de firma\n\n### A√ß√£o Necess√°ria:\n**URGENTE:** Gestor comercial deve entrar em contato com o cliente para providenciar:\n1. Contrato Social com registro v√°lido\n2. RG leg√≠vel do s√≥cio principal\n3. Procura√ß√£o com firma reconhecida\n\n### Impacto:\nEsses documentos s√£o obrigat√≥rios e impedem o prosseguimento do processo.",
                "acoes_requeridas": [
                    {
                        "item": "Contrato Social",
                        "acao": "SOLICITAR_AO_GESTOR",
                        "parametros": {
                            "detalhes": "Documento sem n√∫mero de registro na Junta Comercial"
                        }
                    },
                    {
                        "item": "RG do s√≥cio",
                        "acao": "SOLICITAR_AO_GESTOR",
                        "parametros": {
                            "detalhes": "Documento ileg√≠vel, necess√°rio nova c√≥pia"
                        }
                    }
                ]
            },
            "pendencia_nao_bloqueante": {
                "status_geral": "Pendencia_NaoBloqueante",
                "relatorio_detalhado": "## ‚ö†Ô∏è PEND√äNCIAS N√ÉO CR√çTICAS\n\n### Documentos Principais:\n- ‚úÖ Contrato Social: V√°lido e registrado\n- ‚úÖ Documentos dos s√≥cios: Completos\n- ‚úÖ Procura√ß√£o: V√°lida\n\n### Pend√™ncias Identificadas:\n- ‚ö†Ô∏è Cart√£o CNPJ: Ausente ou desatualizado (>90 dias)\n- ‚ö†Ô∏è Certid√£o Simplificada: Necess√°ria devido √† idade do contrato\n\n### A√ß√µes Autom√°ticas:\n- ü§ñ Cart√£o CNPJ ser√° gerado automaticamente via API\n- üìã Equipe de cadastro ser√° notificada para emitir Certid√£o Simplificada\n\n### Status:\nDocumenta√ß√£o principal aprovada. Pend√™ncias ser√£o resolvidas internamente.",
                "acoes_requeridas": [
                    {
                        "item": "Cart√£o CNPJ",
                        "acao": "GERAR_DOCUMENTO_VIA_API",
                        "parametros": {
                            "cnpj": "12345678000195",
                            "detalhes": "Cart√£o CNPJ ausente ou com mais de 90 dias"
                        }
                    },
                    {
                        "item": "Certid√£o Simplificada",
                        "acao": "NOTIFICAR_EQUIPE_CADASTRO",
                        "parametros": {
                            "detalhes": "Contrato Social com mais de 3 anos, necess√°ria certid√£o atualizada"
                        }
                    }
                ]
            }
        }
        
        if scenario not in scenarios:
            raise HTTPException(
                status_code=400, 
                detail=f"Scenario inv√°lido. Op√ß√µes: {list(scenarios.keys())}"
            )
        
        test_crew_response = scenarios[scenario]
        
        logger.info(f"üß™ TESTE CEN√ÅRIO: {scenario.upper()} para card {card_id}")
        logger.info(f"üìã Status: {test_crew_response.get('status_geral')}")
        
        # Executar orquestrador
        orchestration_result = await handle_crewai_analysis_result(card_id, test_crew_response)
        
        return {
            "success": True,
            "card_id": card_id,
            "scenario": scenario,
            "test_crew_response": test_crew_response,
            "orchestration_result": orchestration_result,
            "message": f"Cen√°rio '{scenario}' executado com sucesso",
            "available_scenarios": list(scenarios.keys()),
            "endpoint": "test_orchestrator_scenarios"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erro no teste de cen√°rios: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erro interno: {str(e)}")

@app.post("/test/robust-field-handling")
async def test_robust_field_handling(request: Request):
    """
    Endpoint de prueba para la funcionalidad robusta de manejo de campos Pipefy.
    
    FUNCIONALIDAD:
    - Detecta si el campo 'Informe CrewAI' existe (tiene valor)
    - Si no existe, lo crea autom√°ticamente en la fase actual
    - Inicializa con placeholder para que aparezca en la API
    - Actualiza con el contenido real del informe
    
    SOLUCIONA: El comportamiento espec√≠fico de Pipefy donde los campos
    solo aparecen en la API cuando tienen alg√∫n valor asignado.
    """
    try:
        data = await request.json()
        card_id = data.get('card_id')
        test_content = data.get('test_content', f'üß™ Prueba robusta de campo Pipefy - {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
        
        if not card_id:
            raise HTTPException(status_code=400, detail="card_id es requerido")
        
        logger.info(f"üß™ PRUEBA ROBUSTA: Manejo de campos Pipefy para card: {card_id}")
        logger.info(f"üéØ OBJETIVO: Solucionar comportamiento donde campos sin valor no aparecen en API")
        
        # Ejecutar actualizaci√≥n robusta
        success = await update_pipefy_informe_crewai_field(card_id, test_content)
        
        if success:
            return {
                "success": True,
                "card_id": card_id,
                "test_content": test_content,
                "strategy": "robust_field_handling",
                "features": [
                    "Detecci√≥n autom√°tica de campos existentes",
                    "Creaci√≥n autom√°tica si no existe",
                    "Inicializaci√≥n con placeholder",
                    "Actualizaci√≥n con contenido real",
                    "Manejo del comportamiento espec√≠fico de Pipefy"
                ],
                "message": "Campo manejado exitosamente con estrategia robusta"
            }
        else:
            raise HTTPException(
                status_code=500, 
                detail="Error en manejo robusto de campo"
            )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error en prueba robusta: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error interno: {str(e)}")

@app.get("/debug/pipefy-config")
async def debug_pipefy_config():
    """
    Endpoint de diagn√≥stico para verificar la configuraci√≥n de Pipefy.
    """
    return {
        "pipefy_config": {
            "token_configured": bool(settings.PIPEFY_TOKEN),
            "phase_id_aprovado": PHASE_ID_APROVADO,
            "phase_id_pendencias": PHASE_ID_PENDENCIAS,
            "phase_id_emitir_docs": PHASE_ID_EMITIR_DOCS,
            "field_id_informe": settings.FIELD_ID_INFORME
        },
        "twilio_config": {
            "account_sid_configured": bool(settings.TWILIO_ACCOUNT_SID),
            "auth_token_configured": bool(settings.TWILIO_AUTH_TOKEN),
            "whatsapp_number": settings.TWILIO_WHATSAPP_NUMBER
        },
        "cnpja_config": {
            "api_key_configured": bool(settings.CNPJA_API_KEY)
        }
    }

@app.get("/debug/card-info/{card_id}")
async def debug_card_info(card_id: str):
    """
    Endpoint de diagn√≥stico para obtener informaci√≥n completa de un card.
    """
    if not settings.PIPEFY_TOKEN:
        return {"error": "Token Pipefy n√£o configurado"}
    
    query = """
    query GetCard($cardId: ID!) {
        card(id: $cardId) {
            id
            title
            current_phase {
                id
                name
            }
            pipe {
                id
                name
                phases {
                    id
                    name
                }
            }
            fields {
                field {
                    id
                    label
                    type
                }
                value
            }
        }
    }
    """
    
    variables = {"cardId": card_id}
    headers = {
        "Authorization": f"Bearer {settings.PIPEFY_TOKEN}",
        "Content-Type": "application/json"
    }
    payload = {"query": query, "variables": variables}
    
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(PIPEFY_API_URL, json=payload, headers=headers)
            response.raise_for_status()
            data = response.json()
            
            if "errors" in data:
                return {"error": "GraphQL error", "details": data["errors"]}
            
            card_data = data.get("data", {}).get("card")
            if not card_data:
                return {"error": "Card not found"}
            
            return {
                "card": card_data,
                "phase_analysis": {
                    "current_phase_id": card_data["current_phase"]["id"],
                    "current_phase_name": card_data["current_phase"]["name"],
                    "available_phases": [
                        {"id": phase["id"], "name": phase["name"]} 
                        for phase in card_data["pipe"]["phases"]
                    ],
                    "target_phases": {
                        "aprovado": PHASE_ID_APROVADO,
                        "pendencias": PHASE_ID_PENDENCIAS,
                        "emitir_docs": PHASE_ID_EMITIR_DOCS
                    }
                }
            }
    except Exception as e:
        return {"error": str(e)}

@app.post("/debug/test-move-card")
async def debug_test_move_card(request: Request):
    """
    Endpoint de diagn√≥stico para testar movimiento de card.
    """
    data = await request.json()
    card_id = data.get("card_id")
    phase_id = data.get("phase_id")
    
    if not card_id or not phase_id:
        return {"error": "card_id e phase_id s√£o obrigat√≥rios"}
    
    logger.info(f"üß™ TESTE: Movendo card {card_id} para phase {phase_id}")
    success = await move_pipefy_card_to_phase(card_id, phase_id)
    
    return {
        "success": success,
        "card_id": card_id,
        "phase_id": phase_id,
        "message": "Movimento executado - verificar logs para detalhes"
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8003)