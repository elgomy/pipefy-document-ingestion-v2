#!/usr/bin/env python3
"""
Script de prueba para verificar la integraciÃ³n automÃ¡tica de mÃ©tricas
con el sistema de manejo de errores.
"""

import asyncio
import time
import logging
import sys
from pathlib import Path

# Agregar el directorio src al path
sys.path.insert(0, str(Path(__file__).parent / "src"))

# Importar desde el directorio src correcto
import sys
sys.path.append(str(Path(__file__).parent / "src"))

from utils.error_handler import with_error_handling, RetryConfig, get_metrics_service

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

# Funciones de prueba que simulan APIs externas

@with_error_handling("pipefy", RetryConfig(max_retries=2, base_delay=0.1))
async def test_pipefy_success():
    """Simula una llamada exitosa a Pipefy."""
    await asyncio.sleep(0.1)  # Simular latencia
    return {"status": "success", "data": "pipefy_data"}

@with_error_handling("pipefy", RetryConfig(max_retries=2, base_delay=0.1))
async def test_pipefy_failure():
    """Simula una falla en Pipefy."""
    await asyncio.sleep(0.05)
    raise Exception("Pipefy API error")

@with_error_handling("crewai", RetryConfig(max_retries=1, base_delay=0.1))
async def test_crewai_timeout():
    """Simula un timeout en CrewAI."""
    await asyncio.sleep(0.05)
    raise asyncio.TimeoutError("CrewAI timeout")

@with_error_handling("twilio", RetryConfig(max_retries=1, base_delay=0.1))
async def test_twilio_success():
    """Simula una llamada exitosa a Twilio."""
    await asyncio.sleep(0.2)
    return {"message_sid": "SM123456", "status": "sent"}

@with_error_handling("cnpj")  # Usar configuraciÃ³n por defecto
def test_cnpj_sync_success():
    """Simula una llamada sÃ­ncrona exitosa a CNPJ."""
    time.sleep(0.15)
    return {"cnpj": "12345678000199", "company": "Test Company"}

@with_error_handling("supabase", RetryConfig(max_retries=1, base_delay=0.1))
async def test_supabase_failure():
    """Simula una falla en Supabase."""
    await asyncio.sleep(0.1)
    raise Exception("Database connection error")

async def run_tests():
    """Ejecuta las pruebas y muestra las mÃ©tricas."""
    logger.info("ğŸš€ Iniciando pruebas de integraciÃ³n de mÃ©tricas...")
    
    # Limpiar mÃ©tricas antes de empezar
    if get_metrics_service():
        get_metrics_service().clear_metrics()
    
    # Test 1: Llamadas exitosas
    logger.info("\nğŸ“Š Test 1: Llamadas exitosas")
    try:
        result1 = await test_pipefy_success()
        logger.info(f"âœ… Pipefy success: {result1}")
        
        result2 = await test_twilio_success()
        logger.info(f"âœ… Twilio success: {result2}")
        
        result3 = test_cnpj_sync_success()
        logger.info(f"âœ… CNPJ success: {result3}")
    except Exception as e:
        logger.error(f"âŒ Error inesperado: {e}")
    
    # Test 2: Llamadas con fallos
    logger.info("\nğŸ“Š Test 2: Llamadas con fallos")
    try:
        await test_pipefy_failure()
    except Exception as e:
        logger.info(f"ğŸ”¥ Pipefy failure (esperado): {e}")
    
    try:
        await test_crewai_timeout()
    except Exception as e:
        logger.info(f"â±ï¸ CrewAI timeout (esperado): {e}")
    
    try:
        await test_supabase_failure()
    except Exception as e:
        logger.info(f"ğŸ’¥ Supabase failure (esperado): {e}")
    
    # Test 3: MÃºltiples llamadas para generar estadÃ­sticas
    logger.info("\nğŸ“Š Test 3: MÃºltiples llamadas")
    for i in range(5):
        try:
            await test_pipefy_success()
        except:
            pass
        
        if i % 2 == 0:  # Algunas fallan
            try:
                await test_pipefy_failure()
            except:
                pass
    
    # Mostrar mÃ©tricas finales
    logger.info("\nğŸ“ˆ MÃ‰TRICAS FINALES:")
    metrics_service_instance = get_metrics_service()
    
    if metrics_service_instance:
        all_metrics = metrics_service_instance.get_all_metrics()
        
        for service_name, service_metrics in all_metrics["services"].items():
            logger.info(f"\nğŸ”§ {service_name.upper()}:")
            logger.info(f"  ğŸ“Š Total requests: {service_metrics['total_requests']}")
            logger.info(f"  âœ… Successful: {service_metrics['successful_requests']}")
            logger.info(f"  âŒ Failed: {service_metrics['failed_requests']}")
            logger.info(f"  â±ï¸ Timeouts: {service_metrics['timeout_requests']}")
            logger.info(f"  ğŸ“ˆ Success rate: {service_metrics['success_rate']:.1f}%")
            logger.info(f"  âš¡ Avg response time: {service_metrics['avg_response_time']:.3f}s")
            logger.info(f"  ğŸ”„ Consecutive failures: {service_metrics['consecutive_failures']}")
            logger.info(f"  ğŸš¨ Circuit breaker open: {service_metrics['circuit_breaker_open']}")
        
        # Mostrar alertas
        alerts = metrics_service_instance.get_recent_alerts(hours=1)
        if alerts:
            logger.info(f"\nğŸš¨ ALERTAS RECIENTES ({len(alerts)}):")
            for alert in alerts[-5:]:  # Mostrar Ãºltimos 5
                logger.info(f"  [{alert['level'].upper()}] {alert['service']}: {alert['message']}")
        else:
            logger.info("\nâœ… No hay alertas recientes")
        
        # Mostrar resumen general
        summary = all_metrics["summary"]
        logger.info(f"\nğŸ“‹ RESUMEN GENERAL:")
        logger.info(f"  ğŸ“Š Total requests: {summary['total_requests']}")
        logger.info(f"  âœ… Total successful: {summary['total_successful']}")
        logger.info(f"  âŒ Total failed: {summary['total_failed']}")
        logger.info(f"  ğŸ“ˆ Overall success rate: {summary['overall_success_rate']:.1f}%")
        logger.info(f"  ğŸ”¥ Services with issues: {summary['services_with_issues']}")
    else:
        logger.warning("âš ï¸ Servicio de mÃ©tricas no disponible")

def main():
    """FunciÃ³n principal."""
    try:
        asyncio.run(run_tests())
        logger.info("\nğŸ‰ Pruebas completadas exitosamente!")
    except Exception as e:
        logger.error(f"ğŸ’¥ Error durante las pruebas: {e}")
        raise

if __name__ == "__main__":
    main() 