#!/usr/bin/env python3
"""
Script de prueba final para demostrar la integraciÃ³n completa
del sistema de error handling con mÃ©tricas automÃ¡ticas.
"""

import asyncio
import time
import logging
import sys
from pathlib import Path

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

# Agregar src al path de Python
src_path = Path(__file__).parent / "src"
sys.path.insert(0, str(src_path))

# Importar y configurar mÃ©tricas explÃ­citamente
from services.metrics_service import MetricsService, ServiceType
from utils.error_handler import with_error_handling, RetryConfig

# Crear instancia global de mÃ©tricas
metrics_service = MetricsService()

# Patch manual del error handler para usar nuestra instancia
import utils.error_handler as eh
eh._metrics_service = metrics_service
eh.ServiceType = ServiceType

logger.info("ğŸ”§ Sistema de mÃ©tricas configurado manualmente")

# Funciones de prueba decoradas

@with_error_handling("pipefy", RetryConfig(max_retries=2, base_delay=0.1))
async def test_pipefy_success():
    """Simula una llamada exitosa a Pipefy."""
    await asyncio.sleep(0.1)
    return {"status": "success", "card_id": "12345"}

@with_error_handling("pipefy", RetryConfig(max_retries=2, base_delay=0.1))
async def test_pipefy_failure():
    """Simula una falla en Pipefy."""
    await asyncio.sleep(0.05)
    raise Exception("Pipefy API rate limit exceeded")

@with_error_handling("crewai", RetryConfig(max_retries=1, base_delay=0.1))
async def test_crewai_timeout():
    """Simula un timeout en CrewAI."""
    await asyncio.sleep(0.05)
    raise asyncio.TimeoutError("CrewAI service timeout")

@with_error_handling("twilio")
async def test_twilio_success():
    """Simula una llamada exitosa a Twilio."""
    await asyncio.sleep(0.15)
    return {"message_sid": "SM123456", "status": "sent"}

@with_error_handling("cnpj", RetryConfig(max_retries=1, base_delay=0.1))
def test_cnpj_sync_success():
    """Simula una llamada sÃ­ncrona exitosa a CNPJ."""
    time.sleep(0.12)
    return {"cnpj": "12345678000199", "company": "Test Company"}

@with_error_handling("supabase", RetryConfig(max_retries=1, base_delay=0.1))
async def test_supabase_failure():
    """Simula una falla en Supabase."""
    await asyncio.sleep(0.08)
    raise ConnectionError("Database connection lost")

async def run_final_test():
    """Ejecuta la prueba final completa."""
    logger.info("ğŸš€ Iniciando prueba final de integraciÃ³n completa...")
    
    # Limpiar mÃ©tricas
    metrics_service.clear_metrics()
    metrics_service.clear_alerts()
    logger.info("ğŸ§¹ MÃ©tricas limpiadas")
    
    # Test 1: Operaciones exitosas
    logger.info("\nğŸ“Š Test 1: Operaciones exitosas")
    try:
        result1 = await test_pipefy_success()
        logger.info(f"âœ… Pipefy: {result1}")
        
        result2 = await test_twilio_success()
        logger.info(f"âœ… Twilio: {result2}")
        
        result3 = test_cnpj_sync_success()
        logger.info(f"âœ… CNPJ: {result3}")
    except Exception as e:
        logger.error(f"âŒ Error inesperado: {e}")
    
    # Test 2: Operaciones con fallos
    logger.info("\nğŸ“Š Test 2: Operaciones con fallos (con retry automÃ¡tico)")
    
    try:
        await test_pipefy_failure()
    except Exception as e:
        logger.info(f"ğŸ”¥ Pipefy failure (esperado): {e}")
    
    try:
        await test_crewai_timeout()
    except Exception as e:
        logger.info(f"â±ï¸ CrewAI timeout (esperado): {e}")
    
    try:
        await test_supabase_failure()
    except Exception as e:
        logger.info(f"ğŸ’¥ Supabase failure (esperado): {e}")
    
    # Test 3: MÃºltiples operaciones para generar estadÃ­sticas
    logger.info("\nğŸ“Š Test 3: MÃºltiples operaciones")
    
    for i in range(5):
        try:
            await test_pipefy_success()
        except:
            pass
        
        if i % 2 == 0:
            try:
                await test_pipefy_failure()
            except:
                pass
    
    # Operaciones sÃ­ncronas adicionales
    for i in range(3):
        try:
            test_cnpj_sync_success()
        except:
            pass
    
    # Mostrar mÃ©tricas capturadas automÃ¡ticamente
    show_captured_metrics()

def show_captured_metrics():
    """Muestra las mÃ©tricas capturadas automÃ¡ticamente por el decorador."""
    logger.info("\nğŸ“ˆ MÃ‰TRICAS CAPTURADAS AUTOMÃTICAMENTE:")
    
    all_metrics = metrics_service.get_all_metrics()
    
    # Mostrar mÃ©tricas por servicio
    for service_name, service_metrics in all_metrics["services"].items():
        if service_metrics['total_requests'] > 0:
            logger.info(f"\nğŸ”§ {service_name.upper()}:")
            logger.info(f"  ğŸ“Š Total requests: {service_metrics['total_requests']}")
            logger.info(f"  âœ… Successful: {service_metrics['successful_requests']}")
            logger.info(f"  âŒ Failed: {service_metrics['failed_requests']}")
            logger.info(f"  â±ï¸ Timeouts: {service_metrics['timeout_requests']}")
            logger.info(f"  ğŸ“ˆ Success rate: {service_metrics['success_rate']:.1f}%")
            logger.info(f"  âš¡ Avg response time: {service_metrics['avg_response_time_seconds']:.3f}s")
            logger.info(f"  ğŸ”„ Consecutive failures: {service_metrics['consecutive_failures']}")
            logger.info(f"  ğŸš¨ Circuit breaker open: {service_metrics['circuit_breaker_open']}")
    
    # Mostrar alertas automÃ¡ticas
    alerts = metrics_service.get_recent_alerts(hours=1)
    if alerts:
        logger.info(f"\nğŸš¨ ALERTAS AUTOMÃTICAS ({len(alerts)}):")
        for alert in alerts:
            logger.info(f"  [{alert['level'].upper()}] {alert['service']}: {alert['message']}")
    else:
        logger.info("\nâœ… No se generaron alertas automÃ¡ticas")
    
    # Resumen general
    summary = all_metrics["summary"]
    logger.info(f"\nğŸ“‹ RESUMEN GENERAL:")
    logger.info(f"  ğŸ“Š Total requests: {summary['total_requests']}")
    logger.info(f"  âœ… Total successful: {summary['total_successful']}")
    logger.info(f"  âŒ Total failed: {summary['total_failed']}")
    logger.info(f"  ğŸ“ˆ Overall success rate: {summary['overall_success_rate']:.1f}%")
    logger.info(f"  ğŸ”¥ Services with failures: {summary['services_with_failures']}")
    logger.info(f"  ğŸš¨ Services with circuit open: {summary['services_with_circuit_open']}")
    
    # Exportar mÃ©tricas
    export_file = "final_metrics_export.json"
    metrics_service.export_metrics(export_file)
    logger.info(f"\nğŸ’¾ MÃ©tricas exportadas a: {export_file}")

def main():
    """FunciÃ³n principal."""
    try:
        asyncio.run(run_final_test())
        
        logger.info("\nğŸ‰ Â¡PRUEBA FINAL COMPLETADA EXITOSAMENTE!")
        logger.info("\n" + "="*60)
        logger.info("âœ¨ INTEGRACIÃ“N COMPLETA FUNCIONANDO:")
        logger.info("  ğŸ”§ Error handling automÃ¡tico con retry logic")
        logger.info("  ğŸ“Š MÃ©tricas capturadas automÃ¡ticamente")
        logger.info("  ğŸš¨ Alertas generadas automÃ¡ticamente")
        logger.info("  ğŸ”„ Circuit breakers funcionando")
        logger.info("  â±ï¸ Timeouts detectados automÃ¡ticamente")
        logger.info("  ğŸ“ˆ EstadÃ­sticas en tiempo real")
        logger.info("="*60)
        logger.info("ğŸ” Revisa final_metrics_export.json para detalles completos")
        
    except Exception as e:
        logger.error(f"ğŸ’¥ Error en la prueba final: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main() 